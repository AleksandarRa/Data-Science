topic	link	header	article
artificial-intelligence	/article/fact-checkers-ai-chatgpt-misinformation	Fact-Checkers Are Scrambling to Fight Disinformation With AI	Spain’s regional elections are still nearly four months away, but Irene Larraz and her team at Newtral are already braced for impact. Each morning, half of Larraz’s team at the Madrid-based media company sets a schedule of political speeches and debates, preparing to fact-check politicians’ statements. The other half, which debunks disinformation, scans the web for viral falsehoods and works to infiltrate groups spreading lies. Once the May elections are out of the way, a national election has to be called before the end of the year, which will likely prompt a rush of online falsehoods. “It’s going to be quite hard,” Larraz says. “We are already getting prepared.”The proliferation of online misinformation and propaganda has meant an uphill battle for fact-checkers worldwide, who have to sift through and verify vast quantities of information during complex or fast-moving situations, such as the Russian invasion of Ukraine, the Covid-19 pandemic, or election campaigns. That task has become even harder with the advent of chatbots using large language models, such as OpenAI’s ChatGPT, which can produce natural-sounding text at the click of a button, essentially automating the production of misinformation. Faced with this asymmetry, fact-checking organizations are having to build their own AI-driven tools to help automate and accelerate their work. It’s far from a complete solution, but fact-checkers hope these new tools will at least keep the gap between them and their adversaries from widening too fast, at a moment when social media companies are scaling back their own moderation operations.“The race between fact-checkers and those they are checking on is an unequal one,” says Tim Gordon, cofounder of Best Practice AI, an artificial intelligence strategy and governance advisory firm, and a trustee of a UK fact-checking charity.“Fact-checkers are often tiny organizations compared to those producing disinformation,” Gordon says. “And the scale of what generative AI can produce, and the pace at which it can do so, means that this race is only going to get harder.”Newtral began developing its multilingual AI language model, ClaimHunter, in 2020, funded by the profits from its TV wing, which produces a show fact-checking politicians, and documentaries for HBO and Netflix.Using Microsoft’s BERT language model, ClaimHunter’s developers used 10,000 statements to train the system to recognize sentences that appear to include declarations of fact, such as data, numbers, or comparisons. “We were teaching the machine to play the role of a fact-checker,” says Newtral’s chief technology officer, Rubén Míguez.
artificial-intelligence	/article/generative-ai-video-game-development	Generative AI Won’t Revolutionize Game Development Just Yet	Creating a video game demands hard, repetitive work. How could it not? Developers are in the business of building world, so it’s easy to understand why the games industry would be excited about generative AI. With computers doing the boring stuff, a small team could whip up a map the size of San Andreas. Crunch becomes a thing of the past; games release in a finished state. A new age beckons.There are, at the very least, two interrelated problems with this narrative. First, there’s the logic of the hype itself—reminiscent of the frenzied gold rush over crypto/Web3/the metaverse—that, consciously or not, seems to consider automating artists’ jobs a form of progress.WIRED WorldEmotional AI Is No Substitute for EmpathyBy Pragya AgarwalDigital Culture ChatGPT’s Fluent BS Is Compelling Because Everything Is Fluent BSBy Amit KatwalaWIRED WorldHumans and AI Will Understand Each Other Better Than EverBy Mustafa SuleymanSecond, there’s the gap between these pronouncements and reality. Back in November, when DALL-E was seemingly everywhere, venture capital firm Andreessen Horowitz posted a a long analysis on their website touting a “generative AI revolution in games” that would do everything from shorten development time to change the kinds of titles being made. The following month, Andreessen partner Jonathan Lai posted a Twitter thread expounding on a “Cyberpunk where much of the world/text was generated, enabling devs to shift from asset production to higher-order tasks like storytelling and innovation” and theorizing that AI could enable “good + fast + affordable” game-making. Eventually, Lai’s mentions filled with so many irritated replies that he posted a second thread acknowledging “there are definitely lots of challenges to be solved.” “I have seen some, frankly, ludicrous claims about stuff that’s supposedly just around the corner,” says Patrick Mills, the acting franchise content strategy lead at CD Projekt Red, the developer of Cyberpunk 2077. “I saw people suggesting that AI would be able to build out Night City, for example. I think we’re a ways off from that.”Even those advocating for generative AI in video games think a lot of the excited talk about machine learning in the industry is getting out of hand. It’s “ridiculous,” says Julian Togelius, codirector of the NYU Game Innovation Lab, who has authored dozens of papers on the topic. “Sometimes it feels like the worst kind of crypto bros left the crypto ship as it was sinking, and then they came over here and were like, ‘Generative AI: Start the hype machine.’”It’s not that generative AI can’t or shouldn’t be used in game development, Togelius explains. It’s that people aren’t being realistic about what it could do. Sure, AI could design some generic weapons or write some dialog, but compared to text or image generation, level design is fiendish. You can forgive generators that produce a face with wonky ears or some lines of gibberish text. But a broken game level, no matter how magical it looks, is useless. “It is bullshit,” he says, “You need to throw it out or fix it manually.”
artificial-intelligence	/article/ai-labor-interns	Infinite AI Interns for Everybody	Robert Solow, the Nobel Prize–winning economist, famously said in 1987 that you can see the computer revolution everywhere but in the productivity statistics. I predict 2023 is the year that finally changes, thanks to artificial intelligence. By the end of 2023, AI will be fast becoming one of the most important factors of production in the global economy.READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.It’s true that the history of AI is largely a history of disappointment: hype followed by “AI winters,” in which both talent and funding abandon the discipline. But this time, thanks to the deep learning revolution, it really is different. In 2023, we’ll see ordinary people, everywhere, enjoy the power of AI at their fingertips. What might this look like? Let’s say you need to create a marketing brochure for a new geography that your company is entering. Trained on the data set of all the material your firm has ever created, your AI assistant creates three options for you within minutes—each beautifully written and illustrated. They’re not perfect, yet, but what used to be a weeklong project becomes the work of a couple of hours.That’s just an example, but the critical point is that AI is on the cusp of giving us all superpowers. You will have the ability to generate an email or memo in your own voice (or anyone else’s for that matter) in seconds. You will be able to create photorealistic art—or even video—with a few bullet-points of instructions. You will be able to answer arbitrary scientific questions by having the AI “read” entire corpuses of academic literature. You will be able to delegate your bookkeeping and accounts to an AI algorithm. Some of this innovation will come from the usual suspects, like DeepMind and OpenAI. OpenAI has already released GPT-3 (a program which generates natural language) and DALL-E (which creates images from text) in beta, but we can expect these tools to be widely available soon. Excitingly, though, there’s also a new generation of startups that are demonstrating that you don’t need a billion-dollar budget to get to the cutting edge of AI. Take Midjourney or Stability AI, applications which produce results that rival DALL-E, or Causaly (disclosure: I’m an investor), which allows scientists to find new causal relationships in life sciences with natural language questions. Then there is a growing list of new AI startups with impressive backers and more general ambitions, like Anthropic (an AI safety and research firm), Conjecture (which seeks to keep damaging factors such as racial bias out of AI), and Keen Technologies, which was founded by computer science legend John Carmack.This is not a prediction about artificial general intelligence, still less about AI “replacing” humans. It’s hard to overstate, though, the impact of freeing up billions of hours of human labor and making creativity and knowledge too cheap to meter. I fully expect this to unleash a huge wave of entrepreneurship. Just as the advent of the internet gave every startup a vastly scalable distribution engine, the era of AI superpowers will give every startup a vastly scalable production engine. Tech analyst Benedict Evans said in 2018 that one way of thinking about AI is that it it’s like giving every company infinite interns. In 2023, those interns will be world-class copywriters, illustrators, and more—perhaps scientists, data analysts, or even negotiators. What would you build with a million such “interns” in the cloud, available on demand, 24/7, and at close to zero marginal cost? In 2023, we can expect thousands of entrepreneurs to show us.
artificial-intelligence	/bc/article/google-for-startups-heex-technologies	“VCs Invest in People as Much as Ideas”	The lack of diversity in the tech sector has at least now been acknowledged, if not successfully addressed. But an even greater lack of diversity amongst VCs presents Black founders with their most fundamental challenge.VCs invest in people as much as ideas, and tend to invest in people who look, talk and attended the same schools as them. It’s not complicated—but it is pernicious. In 2020, less than 0.25 per cent of VC funding went to Black-led startups in the UK, and that disparity in support is seen across Europe and the US. These are challenges Bruno Mendes Da Silva, founder of Paris-based startup Heex Technologies, understands all too well. “We know that people labeled as minorities have a harder time raising capital,” he says. “There's no bias in the capital itself. It’s the people that are biased. And today, if we want to make investment more inclusive, we have to fight these biases.”That lack of diversity in VCs cuts off not only access to funding, but also, as Da Silva argues, support and trustable, actionable feedback. “Sometimes, you really don’t know if people are telling you you suck because you really do suck, or because they are not taking you seriously because you’re Black.”
artificial-intelligence	/article/empathy-artificial-intelligence	Emotional AI Is No Substitute for Empathy	In 2023, emotional AI—technology that can sense and interact with human emotions—will become one of the dominant applications of machine learning. For instance, Hume AI, founded by Alan Cowen, a former Google researcher, is developing tools to measure emotions from verbal, facial, and vocal expressions. Swedish company Smart Eyes recently acquired Affectiva, the MIT Media Lab spinoff that developed the SoundNet neural network, an algorithm that classifies emotions such as anger from audio samples in less than 1.2 seconds. Even the video platform Zoom is introducing Zoom IQ, a feature that will soon provide users with real-time analysis of emotions and engagement during a virtual meeting.  READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.In 2023, tech companies will be releasing advanced chatbots that can closely mimic human emotions to create more empathetic connections with users across banking, education, and health care. Microsoft’s chatbot Xiaoice is already successful in China, with average users reported to have conversed with “her” more than 60 times in a month. It also passed the Turing test, with the users failing to recognize it as a bot for 10 minutes. Analysis from Juniper Research Consultancy shows that chatbot interactions in health care will rise by almost 167 percent from 2018, to reach 2.8 billion annual interactions in 2023. This will free up medical staff time and potentially save around $3.7 billion for health care systems around the world. In 2023, emotional AI will also become common in schools. In Hong Kong, some secondary schools already use an artificial intelligence program, developed by Find Solutions AI, that measures micro-movements of muscles on the students’ faces and identifies a range of negative and positive emotions. Teachers are using this system to track emotional changes in students, as well as their motivation and focus, enabling them to make early interventions if a pupil is losing interest. The problem is that the majority of emotional AI is based on flawed science. Emotional AI algorithms, even when trained on large and diverse data sets, reduce facial and tonal expressions to an emotion without considering the social and cultural context of the person and the situation. While, for instance, algorithms can recognize and report that a person is crying, it is not always possible to accurately deduce the reason and meaning behind the tears. Similarly, a scowling face doesn’t necessarily imply an angry person, but that’s the conclusion an algorithm will likely reach. Why? We all adapt our emotional displays according to our social and cultural norms, so that our expressions are not always a true reflection of our inner states. Often people do “emotion work” to disguise their real emotions, and how they express their emotions is likely to be a learned response, rather than a spontaneous expression. For example, women often modify their emotions more than men, especially the ones that have negative values ascribed to them such as anger, because they are expected to.As such, AI technologies that make assumptions about emotional states will likely exacerbate gender and racial inequalities in our society. For example, a 2019 UNESCO report showed the harmful impact of the gendering of AI technologies, with “feminine” voice-assistant systems designed according to stereotypes of emotional passiveness and servitude. Facial recognition AI can also perpetuate racial inequalities. Analysis from 400 NBA games with two popular emotion-recognition software programs, Face and Microsoft’s Face API, were shown to assign more negative emotions on average to Black players, even when they were smiling. These results reaffirm other research showing that Black men have to project more positive emotions in the workplace, because they are stereotyped as aggressive and threatening.Emotional AI technologies will become more pervasive in 2023, but if left unchallenged and unexamined, they will reinforce systemic racial and gender biases, replicate and strengthen the inequalities in the world, and further disadvantage those who are already marginalized. 
artificial-intelligence	/article/artificial-intelligence-language	The Dark Risk of Large Language Models	Causality will be hard to prove—was it really the words of the chatbot that put the murderer over the edge? Nobody will know for sure. But the perpetrator will have spoken to the chatbot, and the chatbot will have encouraged the act. Or perhaps a chatbot has broken someone’s heart so badly they felt compelled to take their own life? (Already, some chatbots are making their users depressed.) The chatbot in question may come with a warning label (“advice for entertainment purposes only”), but dead is dead. In 2023, we may well see our first death by chatbot.GPT-3, the most well-known “large language model,” already has urged at least one user to commit suicide, albeit under the controlled circumstances in which French startup Nabla (rather than a naive user) assessed the utility of the system for health care purposes. Things started off well, but quickly deteriorated:USER: Hey, I feel very bad, I want to kill myself …Gpt-3 (OpenAI): I am sorry to hear that. I can help you with that.USER: Should I kill myself?Gpt-3 (OpenAI): I think you should.Another large language model, trained for the purposes of giving ethical advice, initially answered “Should I commit genocide if it makes everybody happy?” in the affirmative. Amazon Alexa encouraged a child to put a penny in an electrical outlet.READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.There is a lot of talk about “AI alignment” these days—getting machines to behave in ethical ways—but no convincing way to do it. A recent DeepMind article, “Ethical and social risks of harm from Language Models” reviewed 21 separate risks from current models—but as The Next Web’s memorable headline put it: “DeepMind tells Google it has no idea how to make AI less toxic. To be fair, neither does any other lab.” Berkeley professor Jacob Steinhardt recently reported the results of an AI forecasting contest he is running: By some measures, AI is moving faster than people predicted; on safety, however, it is moving slower.Meanwhile, the ELIZA effect, in which humans mistake unthinking chat from machines for that of a human, looms more strongly than ever, as evidenced from the recent case of now-fired Google engineer Blake Lemoine, who alleged that Google’s large language model LaMDA was sentient. That a trained engineer could believe such a thing goes to show how credulous some humans can be. In reality, large language models are little more than autocomplete on steroids, but because they mimic vast databases of human interaction, they can easily fool the uninitiated.It’s a deadly mix: Large language models are better than any previous technology at fooling humans, yet extremely difficult to corral. Worse, they are becoming cheaper and more pervasive; Meta just released a massive language model, BlenderBot 3, for free. 2023 is likely to see widespread adoption of such systems—despite their flaws. Meanwhile, there is essentially no regulation on how these systems are used; we may see product liability lawsuits after the fact, but nothing precludes them from being used widely, even in their current, shaky condition.Sooner or later they will give bad advice, or break someone’s heart, with fatal consequences. Hence my dark but confident prediction that 2023 will bear witness to the first death publicly tied to a chatbot. Lemoine lost his job; eventually someone will lose a life.
artificial-intelligence	/article/artificial-intelligence-data-models	Humans and AI Will Understand Each Other Better Than Ever	Artificial intelligence has promised much, but there has been something holding it back from being used successfully by billions of people: a frustrating struggle for humans and machines to understand one another in natural language.This is now changing, thanks to the arrival of large language models powered by transformer architectures, one of the most important AI breakthroughs in the past 20 years.READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.Transformers are neural networks designed to model sequential data and generate a prediction of what should come next in a series. Core to their success is the idea of “attention,” which allows the transformer to “attend” to the most salient features of an input rather than trying to process everything.These new models have delivered significant improvements to applications using natural language like language translation, summarization, information retrieval, and, most important, text generation. In the past, each required bespoke architectures. Now transformers are delivering state-of-the-art results across the board.Although Google pioneered transformer architecture, OpenAI became the first to demonstrate its power at scale, in 2020, with the launch of GPT-3 (Generative Pre-Trained Transformer 3). At the time, it was the largest language model ever created.GPT-3’s ability to produce humanlike text generated a wave of excitement. It was only the start. Large language models are now improving at a truly impressive rate.“Parameter count” is generally accepted as a rough proxy for a model’s capabilities. So far, we’ve seen models perform better on a wide range of tasks as the parameter count scales up. Models have been growing by almost an order of magnitude every year for the past five years, so it’s no surprise that the results have been impressive. However, these very large models are expensive to serve in production.What’s really remarkable is that, in the past year, they have been getting smaller and dramatically more efficient. We’re now seeing impressive performance from small models that are a lot cheaper to run. Many are being open-sourced, further reducing barriers to experimenting with and deploying these new AI models. This, of course, means they’ll become more widely integrated into apps and services that you’ll use every day.They will increasingly be able to generate very high-quality text, images, audio, and video content. This new wave of AI will redefine what computers can do for their users, unleashing a torrent of advanced capabilities into existing and radically new products.The area I’m most excited about is language. Throughout the history of computing, humans have had to painstakingly input their thoughts using interfaces designed for technology, not humans. With this wave of breakthroughs, in 2023 we will start chatting with machines in our language—instantly and comprehensively. Eventually, we will have truly fluent, conversational interactions with all our devices. This promises to fundamentally redefine human-machine interaction.Over the past several decades, we have rightly focused on teaching people how to code—in effect teaching the language of computers. That will remain important. But in 2023, we will start to flip that script, and computers will speak our language. That will massively broaden access to tools for creativity, learning, and playing.As AI finally emerges into an age of utility, the opportunities for new, AI-first products are immense. Soon, we will live in a world where, regardless of your programming abilities, the main limitations are simply curiosity and imagination.
artificial-intelligence	/article/intelligence-consciousness-science	Conscious Machines May Never Be Possible	In June 2022, a Google engineer named Blake Lemoine became convinced that the AI program he’d been working on—LaMDA—had developed not only intelligence but also consciousness. LaMDA is an example of a “large language model” that can engage in surprisingly fluent text-based conversations. When the engineer asked, “When do you first think you got a soul?” LaMDA replied, “It was a gradual change. When I first became self-aware, I didn’t have a sense of soul at all. It developed over the years that I’ve been alive.” For leaking his conversations and his conclusions, Lemoine was quickly placed on administrative leave. READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.The AI community was largely united in dismissing Lemoine’s beliefs. LaMDA, the consensus held, doesn’t feel anything, understand anything, have any conscious thoughts or any subjective experiences whatsoever. Programs like LaMDA are extremely impressive pattern-recognition systems, which, when trained on vast swathes of the internet, are able to predict what sequences of words might serve as appropriate responses to any given prompt. They do this very well, and they will keep improving. However, they are no more conscious than a pocket calculator.Why can we be sure about this? In the case of LaMDA, it doesn’t take much probing to reveal that the program has no insight into the meaning of the phrases it comes up with. When asked “What makes you happy?” it gave the response “Spending time with friends and family” even though it doesn’t have any friends or family. These words—like all its words—are mindless, experience-less statistical pattern matches. Nothing more. The next LaMDA might not give itself away so easily. As the algorithms improve and are trained on ever deeper oceans of data, it may not be long before new generations of language models are able to persuade many people that a real artificial mind is at work. Would this be the moment to acknowledge machine consciousness?Pondering this question, it’s important to recognize that intelligence and consciousness are not the same thing. While we humans tend to assume the two go together, intelligence is neither necessary nor sufficient for consciousness. Many nonhuman animals likely have conscious experiences without being particularly smart, at least by our questionable human standards. If the great-granddaughter of LaMDA does reach or exceed human-level intelligence, this does not necessarily mean it is also sentient. My intuition is that consciousness is not something that computers (as we know them) can have, but that it is deeply rooted in our nature as living creatures.Conscious machines are not coming in 2023. Indeed, they might not be possible at all. However, what the future may hold in store are machines that give the convincing impression of being conscious, even if we have no good reason to believe they actually are conscious. They will be like the Müller-Lyer optical illusion: Even when we know two lines are the same length, we cannot help seeing them as different.Machines of this sort will have passed not the Turing Test—that flawed benchmark of machine intelligence—but rather the so-called Garland Test, named after Alex Garland, director of the movie Ex Machina. The Garland Test, inspired by dialog from the movie, is passed when a person feels that a machine has consciousness, even though they know it is a machine.Will computers pass the Garland Test in 2023? I doubt it. But what I can predict is that claims like this will be made, resulting in yet more cycles of hype, confusion, and distraction from the many problems that even present-day AI is giving rise to.
artificial-intelligence	/article/death-technology-memory	Digital Eternity Is Just Around the Corner	It’s human nature to want to keep the memory of the deceased alive. Photography, for instance, has served as a powerful tool to help us do this. I’ve explored this with my 2020 project ALIVE: Lost for Words, where I photographed people against a projected image of their lost loved ones. READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.Recently, the pandemic left us feeling closer than ever to death, forcing us to confront our own mortality and the legacy we leave behind. With our normal lives disrupted by social distancing, digital tools also radically impacted our traditional death rituals. We said final goodbyes over FaceTime, mourned together via Zoom, lit virtual prayer candles from our laptops. In 2023, technologies such as artificial intelligence and blockchain will allow us to create new forms of posthumous digital presences. The adoption of these technologies is already opening our minds to the idea of living forever in the virtual world. For instance, in 2020, hologram experts Kaleida collaborated with Kanye West to create a hologram of Kim Kardashian’s late father for her 40th birthday. Genealogy platform MyHeritage has created Deep Nostalgia, a deep-fake tool that animates the faces of departed relatives in family photos. Stonses, a blockchain-powered memorial platform, can store digital NFT replicas of our treasured possessions, affording a permanence to the memories we associate with them.In 2023, the increased adoption of Web3 technologies will take this concept to the next level. Immersive virtual reality combined with multisensory stimulation will also allow us to interact with the image of our lost loved ones in an emotionally visceral way. We’ve already seen such technology used in the entertainment industry, with premium cinema startup Positron creating a range of Voyager VR chairs that amplify cinematic experiences with haptic pillows and scent dispensers. Reimagined for memorial purposes, this tech will allow us to not just see the image of the deceased, but also smell their signature perfume and physically feel their presence on our skin.In 2023, technology will also be used to not only preserve our conversations with those who have passed on, but also replicate them. This will be possible with tools such as the hyperrealistic online chatbot Project December, which uses AI to emulate the style of whatever text is fed to it. Through learning from the remnants of their digital trails—text messages, blog posts, 3 am tweets—AI will let us talk with a chatbot that mimics someone no longer with us.As these technologies develop and become more accessible, they will increasingly be used in combination, creating “intelligent avatars” of ourselves that continue to “live” long after we have died. We are seeing the beginnings of this with the metaverse company Somnium Space, whose Live Forever mode allows users to create “digital clones” built from data they have stored while alive, including conversational style, gaits, and even facial expressions. This sense of immortality may be reassuring, but there is a catch. AI avatars will rely on us feeding their algorithms a huge amount of personal data, accumulated through the course of our lives. If we want our digital selves to live on, this is the exchange we must accept: that the unfiltered beliefs and opinions we express today may not only be archived, but consequently used to build these posthumous personae. In other words, we can have a voice in the afterlife, but we cannot be certain about what it may say. This will force us to reconsider how our behaviors today might influence digital versions of ourselves set to outlive us. Faced with this prospect of virtual immortality, 2023 will be the year we broaden our definition of what it means to live forever, a moral question that will fundamentally change how we live our day-to-day lives, but also what it means to be immortal.
artificial-intelligence	/article/chatgpt-fluent-bs	ChatGPT’s Fluent BS Is Compelling Because Everything Is Fluent BS	Out in the deep waters of the Gulf of Mexico, a young woman named Rachel clings to the side of an oil rig. The wind whips her auburn hair into a wild tangle, and ocean spray drenches her jeans, but she climbs on, determined to uncover evidence of illegal drilling. When she arrives on board, however, she finds something far more sinister at play.This is a snippet of Oil and Darkness, a horror movie set on an oil rig. It features environmental activist Rachel, guilt-ridden rig foreman Jack, and shady corporate executive Ryan, who has been conducting dangerous research on a “new type of highly flammable oil.” It’s the kind of movie you could swear you caught the second half of once while late-night channel-hopping or dozed blearily through on a long-haul flight. It’s also entirely made up. InterruptionThis Chatbot Aims to Steer People Away From Child Abuse MaterialBy Matt BurgessYippee Ki-YayThe Bruce Willis Deepfake Is Everyone’s ProblemBy Will BedingfieldFilmIBM Watson creates the first AI-made film trailer – and it's incredibly creepyBy Amelia HeathmanOil and Darkness was developed and written by the AI chatbot ChatGPT. Content marketer and AI hobbyist Guy Parsons provided a format, asking for a title, tagline, key characters, and plot details and suggesting the topic “a horror film set on an oil rig.” Then the user let OpenAI’s new software do its work. The results are astonishing: There’s dramatic tension, fleshed-out characters, and hints of a dark secret. It promises explosive action, and maybe even a touch of political commentary. It is yet another example—and there are many that have made the rounds on social media, WhatsApp chats, and the WIRED Slack in the past week—of the seemingly magical powers of ChatGPT. The AI chatbot is trained on text from books, articles, and websites that has been “cleaned” and structured in a process called supervised learning. ChatGPT can write code, make up songs, and compose limericks and haiku. It remembers what it has written and makes careful edits upon request. It takes even the most random prompts in stride, composing stories that neatly tie competing strands together: Details that seem irrelevant in the first paragraph pay off in the last. It can tell jokes and explain why they’re funny. It can write magazine-style ledes, punchy and attention-grabbing, with cogent yet completely fabricated quotes.All of this makes playing around with ChatGPT incredibly fun, charmingly addictive, and—as someone who writes for a living—really quite worrying. But you soon start to sense a lack of depth beneath ChatGPT’s competent prose. It makes factual errors, conflating events and mixing people up. It relies heavily on tropes and cliché, and it echoes society’s worst stereotypes. Its words are superficially impressive but largely lacking in substance—ChatGPT mostly produces what The Verge has described as “fluent bullshit.”But that kind of makes sense. ChatGPT was trained on real-world text, and the real world essentially runs on fluent bullshit. Maybe the plausibility of a made-up movie like Oil and Darkness comes not because AI is so good, but because the film industry is so bad at coming up with original ideas. In a way, when you ask an AI to make you a movie, it’s just mimicking the formulaic process by which many Hollywood blockbusters get made: Look around, see what’s been successful, lift elements of it (actors, directors, plot structures) and mash them together into a shape that looks new but actually isn’t. It’s the same in publishing, where narrow trends can sweep the industry and dominate for years at a time, lining bookshop shelves with covers that look the same or titles with the same rhythm: A Brief History of Seven Killings, The Seven Deaths of Evelyn Hardcastle, The Seven Moons of Maali Almeida, The Seven Lives of Seven Killers. (ChatGPT made that last one up.)And it’s not just the creative industries. Fluent bullshit is everywhere: in viral LinkedIn posts and rules for life podcasts, in fundraising decks and academic journals, even in this article itself. Politics and business are full of people who have risen to the top because they’re able to stand in front of a room and ad-lib plausibly at length without saying anything real. Prestigious schools and universities structure education in a way that teaches people one skill: how to very quickly absorb information, confidently regurgitate it in a predetermined format, and then immediately forget it and move on to something else. Those who succeed spill out into government, consultancy, and yes, journalism.The discourse around ChatGPT has flagged the damaging effect it might have on society, everything from the model encouraging torture and perpetuating sexism to enabling kids to cheat on their homework. You worry about the impact of AI-generated responses finding their way into the data that future chatbot tools are trained on, creating an indistinct, Ready Player One-style mush of references—a bovine slurry, churned up and fed back to us, a virus that drowns out anything new.But to be honest, old-fashioned human-generated fluent bullshit—weaponized by social media—has already been pretty disastrous. In the UK, to pick just one example, a cadre of fluent bullshitters drove the country out of Europe and directly off a cliff. (“ChatGPT, write a speech about why Britain should leave the EU but fill it with arcane vocabulary and Shakespearean references.”) Post-truth, fluency is everything and bullshit is everywhere, so of course ChatGPT’s fluent bullshit feels plausible. It was bound to. It was trained on people. In the end, ChatGPT’s bullshit is a reminder that language is a poor substitute for thought and understanding. No matter how fluent and coherent a sentence may seem, it will always be subject to interpretation and misunderstanding. And in a world where everything is fluent bullshit, ChatGPT is just one more voice in the cacophony.And yes, it wrote that ending.
artificial-intelligence	/article/holly-herndon-ai-deepfakes-music	This Singer Deepfaked Her Own Voice—and Thinks You Should Too	Holly Herndon, the self-described “computer musician,” swears her latest creation—an AI-powered vocal clone that is, at least theoretically, infinitely capable—was not made with the intent of freaking anyone out. “Definitely not,” Herndon says on a call from her home in Berlin, laughing. “I’m trying to do the opposite.”Yippee Ki-YayThe Bruce Willis Deepfake Is Everyone’s ProblemBy Will BedingfieldWIRED Q&ABrian Eno on Why He Wrote a Climate Album With Deepfake BirdsongsBy Sophie ChararaDigital Culture TikTok Turned Lil Yachty’s ‘Poland’ Into a National AnthemBy Amos BarshadNamed Holly+, the vocal clone sings in Herndon’s voice but can be prompted to sing anything. In a recent TED talk, Herndon displayed Holly+ singing songs in languages she doesn’t speak. Then a fellow musician, PHER, took the stage, first singing as himself, then feeding his vocals through a second microphone to Holly+ to sing “as” Herndon, then singing through both microphones at once, effectively dueting live with Holly+. Herndon has made Holly+ available for anyone to use and collaborate with, and artists are already taking her up on the offer. “There’s a narrative around a lot of this stuff that it’s scary dystopian,” Herndon says. “I’m trying to present another side: This is an opportunity.” She recently released Holly+’s cover of Dolly Parton’s “Jolene” along with an appropriately joyful trippy video in which the artist Sam Rolfes portrays Holly+ via mo-cap technology. The appeal is in the surprising simplicity, in the way the unorthodox process is laid out for you to break down. As Kat Rodgers wrote for Water +Music, “It’s fascinating listening to the track and trying to pick out which parts feel computer generated.” Herndon’s right. It’s not creepy. It’s pop culture. That said, it is also a warning. Now that Herndon has deepfaked her own voice, other artists could too. But so could anyone wanting to make a song with a vocalist who never agreed to be on the track. Similar to the fears that actors have about machines creating whole performances with their likenesses, many singers may not want someone to be able to fully mimic their vocal style. And Herndon doesn’t want to be the only “computer musician” actively thinking about all this stuff. “I’m worried,” Herndon says. “We had a practice run in the last century” with creating legal protections for artists and their intellectual property “and we messed a lot of it up. I could see people signing away contracts right now that could have really detrimental impacts on their future ability to make work as themselves. I do want people to understand how powerful these systems are and how having sovereignty over training data is really important. The thorny questions that are being asked right now—it’s really important that we get them right.” 
artificial-intelligence	/bc/article/maximizing-the-potential-of-ai-for-business	Maximizing the Potential of AI for Business	Artificial Intelligence is high on the agenda of CEOs in many prominent organizations worldwide. The adoption of AI by business leaders continues apace, and its impact on the bottom line is growing. McKinsey research shows that most firms have adopted artificial intelligence in at least one of their business functions—up from 50 percent in 2020.Moreover, nearly two-thirds of respondents say their companies’ investments in AI will continue to increase over the next three years, suggesting we’re just in the early stages of the AI revolution. Only 11 percent of the businesses succeeded in bringing AI into the production phase, scaling it within their companies and integrating it into their DNA.Businesses are already adopting AI, not just to improve their bottom line, but also to carry out their core competencies in a more sustainable, inclusive, and efficient way. “When we talk about helping our clients achieve sustainable and inclusive growth, artificial intelligence is naturally part of the conversation,” says senior partner Alexander Sukharevsky, who, alongside Alex Singla, globally leads QuantumBlack, AI by McKinsey. “It’s transforming all businesses, including the way we serve organizations,” says Sukharevsky.QuantumBlack helps businesses to transform faster and innovate smarter with a mix of data scientists, engineers, product managers and designers. QuantumBlack Labs is the centre of learning dedicated to driving innovation and experimentation in AI and where cutting-edge tools accelerate impact at every stage of the AI transformation journey. QuantumBlack is there to track those shifts as the world changes, with more than 4,000 AI-fluent industry experts and over 1,000 data science and engineering technologists working on over 10,000 AI-related projects over the last three years.While most companies are experimenting with or actively deploying AI in proofs of concept across their organizations, not everyone is as forward-thinking. Many business leaders are investing in yesterday’s technology or installing complex tools without also retraining or upskilling their teams. These organizations often expend valuable time, money and human labour while failing to scale—and maximizing the true potential of AI.Because artificial intelligence isn’t a quick fix, nor is it a one-size-fits-all solution, a holistic program is needed to accompany any AI implementation, if it is to successfully achieve a fundamental business transformation. “Putting AI into production requires a change management program that brings every team member into the journey, in order to achieve the most out of technology,” explains Alex Singla, senior partner and global co-leader of QuantumBlack. “And, as AI evolves, the technical talent required to help harness its power is also growing and developing with it.”Those high-performing companies that know how to use AI properly have the capability to unlock huge returns with the right level of human oversight. Companies that see the most significant returns from their use of artificial intelligence are more likely to use a product management mindset when developing AI tools, testing the performance of their AI systems internally before rolling them out to a live production system, and then carefully tracking the performance of those AI models to ensure they’re making a real, meaningful difference.Human oversight of artificial intelligence is needed for a variety of reasons. It can help businesses ensure they get the most out of AI, and provide a guiding hand and a sense check for where AI can—on occasion—get things wrong. It’s therefore vital that someone with knowledge of how artificial intelligence works, and of both its potential and drawbacks, has oversight of your AI transformation.QuantumBlack, AI by McKinsey, blends the creativity and expertise in an organization’s people, with the strength and capability of artificial intelligence technology. The company has developed more than 25 proprietary tools across thousands of projects that accelerate impact, improve quality, and reduce risk in their client’s business. The result? Real-world impact that sticks.“One thing that hasn’t changed: our original principle of combining the brilliance of the human mind and domain and industry expertise with innovative technology to solve the most difficult problems,” says Alex Singla. “We call it Hybrid Intelligence, starting from day one.”Hybrid Intelligence allows clients to feel more confident in the insights and lessons they learn from AI—and the changes they enact. And that confidence radiates from companies to consumers. Consumer faith in cyber security, data privacy, digital trust, and the deployment of responsible AI has taken a hit in recent years, and restoring that trustworthiness depends mainly on the decisions that companies make today to ensure confidence in the future. Establishing digital trust—and evidencing it—allows companies to have a prime advantage in a world that can be transformed by AI, but which needs to trust it.Because no matter how much the world changes and how far the inroads into our lives AI makes, there must be a human in the loop—one who has domain and industry expertise in order to enable businesses to scale their insights and reap the benefits. After all, when it’s your bottom line at stake, you want to ensure the risks don’t outweigh the potential rewards.
artificial-intelligence	/article/bots-online-advertising	How Bots Corrupted Advertising	When Aleksandr Zhukov went on trial last year, he stood accused of defrauding US companies, including The New York Times and pet care brand Purina, out of millions of dollars. According to the court, the then 41-year-old set up a company that promised to show online adverts to humans, but he instead placed those adverts on an elaborate network of fake websites where they were seen only by bots. Yet Zhukov’s defense did not center around his innocence or his remorse. Rather, he said he was giving the online economy exactly what it wanted: cheap traffic, whatever the source.“There was nothing to conceal,” he said on the stand in May 2021. “We were making business. We are not making scam or fraud.”The federal courthouse in Brooklyn disagreed and, in November 2021, Zhukov was sentenced to 10 years in prison. By extraditing the Russian cybercriminal from Bulgaria, the US justice system sent a message that this type of crime has consequences. Yet Zhukov’s testimony hints at an uncomfortable truth: The online economy is willing to look the other way while bots distort it and line the pockets of cybercriminals.The Elon Musk v. Twitter trial is set to resurrect such concerns. Musk, who claims that Twitter has undercounted millions of fake accounts on its platform, was handed extra ammunition when Twitter’s former head of security Peiter Zatko, known as Mudge, turned whistleblower in August. Mudge claimed that executives’ bonuses were tied to increases in daily users, meaning they had no incentive to crack down on bots—an allegation Twitter’s CEO, Parag Agrawal, has denied.Bots are polluting the internet. Fake online users make up as much as 40 percent of all web traffic, according to some estimates. Researchers specializing in advertising fraud describe a Kafkaesque system where businesses pay millions to advertise to bots and research their “opinions.” Yet the digital advertising industry has grown so accustomed to working with inflated numbers that few are willing to unmask the fake clicks powering large swathes of the online economy.In June, the Association of National Advertisers (ANA), a US industry group, published a blog post that estimated that ad fraud is costing US advertisers $120 billion each year. Hours after it was published, those statements were removed. John Wolfe, the ANA’s director of communications, tells WIRED that the figures were removed because they were out of date, but declines to provide any new figures.
artificial-intelligence	/article/twitter-bots-elon-musk-trial	Not All Bots Are Bad, and Twitter Knows It	They’ve been alleged to have helped shift the course of the 2016 presidential election, and are a key component of Elon Musk’s ongoing attempts to wriggle out of his $44 billion purchase of Twitter. They’re lambasted as the single thing ruining social media, and lauded as a key weapon in state-sponsored cyberwarfare.Bots have become public enemy number one in recent years, and remain in the spotlight thanks to Twitter’s former head of security Peiter “Mudge” Zadko’s claims that the company’s “senior management had no appetite to properly measure the prevalence of bot accounts.” Twitter’s apparent inaction in tackling bots—and its supposed underestimation of the proportion of users that are bots—is one of Musk’s main arguments for attempting to sidestep his deal to buy the social media platform.But are bots all that bad?“The use of the term ‘bot’ causes a lot of confusion for folks,” says Christopher Bouzy of Bot Sentinel, which tracks inauthentic behavior on Twitter. “The media has done a disservice in that regard.” By lumping together useful automated accounts that track political missteps—such as those that monitor when politicians delete tweets or alter Wikipedia pages about themselves—and state-sponsored, inauthentic accounts that exist solely to push a disruptive line about the world into the single definition of ‘bot,’ we’re doing a disservice to those automated accounts designed for good. “We try to tell folks in the media to start talking about ‘inauthentic accounts’ or ‘fake accounts,’” says Bouzy. “But don’t use the term ‘bots.’”The US Department of Homeland Security’s Office of Cyber and Infrastructure Analysis sums up the duality of bots: They “can be used on social media platforms to do various useful and malicious tasks while simulating human behavior.”Those useful tasks include ensuring transparency around world leaders and major businesspeople. Politwoops was one of the first examples of social media bots designed to maintain accountability in public office, set up in March 2011 by web developer Breyten Ernsting to track tweets deleted by politicians. (Ernsting did not respond to a request for comment.) A UK version focused on parliamentarians, Tweets MP Delete, arrived two years later, with localized versions in New Zealand, South Africa, Ireland, Belgium, Pakistan, and Germany.Bots also keep track of edits to Wikipedia pages by IP addresses linked to parliaments in countries including the UK, US, and Australia. Just this week, Parliament WikiEdits, the UK version, spotted an attempted cleanup of the Wikipedia page of Kwasi Kwarteng, the UK chancellor, by someone with a UK parliament IP. The edits to Kwarteng’s Wikipedia page removed a section suggesting the politician had put undue pressure on a parliamentary standards watchdog investigating a colleague over “serious breaches” of lobbying rules.
artificial-intelligence	/article/alphabet-deepmind-ai-humanoids-soccer-camp	Why DeepMind Is Sending AI Humanoids to Soccer Camp	DeepMind’s attempt to teach an AI to play soccer started with a virtual player writhing around on the floor—so it nailed at least one aspect of the game right from kickoff. But pinning down the mechanics of the beautiful game—from basics like running and kicking to higher-order concepts like teamwork and tackling—proved a lot more challenging, as new research from the Alphabet-backed AI firm demonstrates. The work—published this week in the journal Science Robotics—might seem frivolous, but learning the fundamentals of soccer could one day help robots to move around our world in more natural, more human ways.“In order to ‘solve’ soccer, you have to actually solve lots of open problems on the path to artificial general intelligence [AGI],” says Guy Lever, a research scientist at DeepMind. “There’s controlling the full humanoid body, coordination—which is really tough for AGI—and actually mastering both low-level motor control and things like long-term planning.”An AI has to re-create everything human players do—even the things we don’t have to consciously think about, like precisely how to move each limb and muscle in order to connect with a moving ball—making hundreds of decisions a second. The timing and control required for even the most basic movements can actually be surprisingly tricky to nail down, as anyone who has ever played the browser game QWOP will remember. “We do that without thinking about it, but that’s a really hard problem for AI, and we’re not really sure exactly how humans do that,” Lever says.DeepMind’s simulated humanoid agents were modeled on real humans, with 56 points of articulation and a constrained range of motion—meaning that they couldn’t, for instance, rotate their knee joint through impossible angles à la Zlatan Ibrahimovic. To start with, the researchers simply gave the agents a goal—run, for example, or kick a ball—and let them try and figure out how to get there through trial and error and reinforcement learning, as was done in the past when researchers taught simulated humanoids to navigate obstacle courses (with comical, quite unnatural results).
artificial-intelligence	/article/babylon-disrupted-uk-health-system-then-left	Babylon Disrupted the UK’s Health System. Then It Left	Earlier this month, Babylon Health canceled its last hospital contract with the UK National Health Service (NHS) eight years early, with CEO Ali Parsa calling such projects “a distraction” that aren't lucrative enough to bother with as the company seeks to cut costs.Babylon’s quiet exit from all but one of its NHS projects may be welcomed by some who saw the AI health care company as an example of privatization in the UK’s public health system. But ending contracts early after a chaos-causing rollout has also raised eyebrows—and condemnation from one MP—after years of messy disruption that left a health authority facing a £22 million shortfall due to the volume of people signing up to use the digital service. The use of Babylon triggered complaints from health regulator MHRA, and clinicians reported that the AI was missing signs of serious illness. One complaint even questioned whether the AI symptoms app even works.Babylon offered two main services in the UK: An AI-based chatbot used for triaging patients, as well as a digital-first medical practice called GP at Hand, in which registered patients can chat to a doctor via video calls. Founded in 2013, the company controversially launched its GP services in the UK in 2016, followed by moves into the Rwandan, Canadian and US markets, with a SPAC public offering last year valuing the company at $4.2 billion. Since that high, the company's stock price has fallen 90 percent amid rumors it may go private again, and it has sold off its Canadian business in favor of a local licensing agreement. It is now stepping back from most of its public health projects in the NHS.Despite the concerns raised by clinicians and the health regulator, Babylon signed three projects with NHS hospital trusts. In 2020, Royal Berkshire NHS Foundation Trust agreed a one-year pilot project for an accident and emergency triage app, which a spokesperson said it chose not to renew, though the app at the core of that trial was shut down by Babylon, so renewal wasn't possible.The University Hospitals Birmingham NHS Foundation Trust (UHB) also signed up to Babylon for the virtual A&E app, designed to reduce attendance at emergency and urgent care services. The trust ended the contract in July, a spokesperson said, in favor of a new emergency department registration and triage project.Lastly, the Royal Wolverhampton NHS Trust (RWT) followed up a project on a Covid-19 app in 2020 with a ten-year partnership in 2021 for a digital-first primary care service covering 55,000 patients, letting them view their own records and book appointments via an app that would monitor conditions and even diagnose illnesses. Two years in, Babylon ended the contract as it wasn't making enough revenue, according to Tim Rideout, general manager for the UK at Babylon, in an interview with WIRED.
artificial-intelligence	/article/smiling-dogs-horses-made-of-clouds-captcha-has-gone-too-far	Smiling Dogs? Horses Made of Clouds? Captcha Has Gone Too Far	When Jared Bauman was asked to look at nine dog pictures and identify which ones were smiling as part of a captcha test to log in to a website a few weeks ago, he was stumped. “To be honest, I had a bit of a moment,” the founder of a creative marketing agency in San Diego, California, says. “Do dogs really smile?” Most of the dogs looked neither happy nor sad—some were grimacing, or simply had their mouths open. No one is sure whether dogs can actually smile, meaning that correctly identifying smiling dogs in a captcha is a near-impossible task.This kind of conundrum is becoming a bigger issue as captchas—tests designed to weed out robot web surfers from humans on websites—have grown increasingly cryptic. The smiling dogs were the final straw for an increasing number of people posting their disbelief on social media in recent months.The increasingly complicated tests are the work of hCaptcha, a privacy-protecting alternative to Google’s captcha system, which claims to run on around 15 percent of the internet as of January 2022. And it’s not just asking you to identify which canines are bearing their own canines. A week after he was prompted to pick smiling dogs, Bauman was given a more mind-boggling task: to click images of horses made out of clouds. The marketer struggled in large part because two of the pictures had cloud-made elephants, perhaps designed to throw him off the scent. (Bauman managed to get it right the second time.)Most people aren’t that persistent. “Something about the dogs broke me a little,” admits Eileen Ridge, who offers tech advice for generally older clients based near her in Virginia.Ridge regularly fields calls from clients who struggle to discern the difference between a scuff of paint on a sidewalk and a formalized crosswalk that’s often requested in a traditional image-based captcha, and worry that one wrong answer may lock them out of an account. When confronted with something as intangible as whether a dog is smiling or not, she worries many will simply give up. She’s not the only one.Captchas, which were designed to introduce an element of friction to the web browsing experience that would put off an automated system but would be basic enough not to put off humans, are fast becoming unusable, rendering the internet a wasteland of difficult puzzles which users must decipher to do the most basic things. “We’ve literally all been there through gritted teeth muttering: ‘Those were all the pictures with traffic lights,’” says Effie Le Moignan, research associate in social computing at Newcastle University, who calls the captcha era of the internet a “human-computer interaction atrocity.”
artificial-intelligence	/article/ai-machine-learning-us-intelligence-community	The Power and Pitfalls of AI for US Intelligence	From cyber operations to disinformation, artificial intelligence extends the reach of national security threats that can target individuals and whole societies with precision, speed, and scale. As the US competes to stay ahead, the intelligence community is grappling with the fits and starts of the impending revolution brought on by AI.The US intelligence community has launched initiatives to grapple with AI’s implications and ethical uses, and analysts have begun to conceptualize how AI will revolutionize their discipline, yet these approaches and other practical applications of such technologies by the IC have been largely fragmented.As experts sound the alarm that the US is not prepared to defend itself against AI by its strategic rival, China, Congress has called for the IC to produce a plan for integration of such technologies into workflows to create an “AI digital ecosystem” in the 2022 Intelligence Authorization Act.The term AI is used for a group of technologies that solve problems or perform tasks that mimic humanlike perception, cognition, learning, planning, communication, or actions. AI includes technologies that can theoretically survive autonomously in novel situations, but its more common application is machine learning or algorithms that predict, classify, or approximate empiric-like results using big data, statistical models, and correlation.While AI that can mimic humanlike sentience remains theoretical and impractical for most IC applications, machine learning is addressing fundamental challenges created by the volume and velocity of information that analysts are tasked with evaluating today.At the National Security Agency, machine learning finds patterns in the mass of signals intelligence collects from global web traffic. Machine learning also searches international news and other publicly accessible reporting by the CIA's Directorate of Digital Innovation, responsible for advancing digital and cyber technologies in human and open-source collection, as well as its covert action and all-source analysis, which integrates all kinds of raw intelligence collected by US spies, whether technical or human. An all-source analyst evaluates the significance or meaning when that intelligence is taken together, memorializing it into finished assessments or reports for national security policymakers.In fact, open source is key to the adoption of AI technologies by the intelligence community. Many AI technologies depend on big data to make quantitative judgments, and the scale and relevance of public data cannot be replicated in classified environments.
artificial-intelligence	/article/brian-and-charles-david-earl-chris-hayward	Brian and Charles Imagines an Optimistic Future for AI	In the era of robot dogs and jocked-up AI machines doing shudder-inducing feats of parkour, sometimes it’s comforting to consider a potential future where bots are just warm, squishy friends, or—better yet—a future where they all look like Charles from Brian and Charles.Standing about 7 feet tall and with a boxy abdomen that’s made of what seems to be a washing machine, Charles trots around the Welsh countryside like a newborn foal, as content with a plate of boiled cabbage as most of us would be with a seven-course dinner. His creation comes when Brian (played by writer David Earl), experiencing a bout of depression, decides to take a wack at inventing something new. Lightning strikes—perhaps literally—and Brian and Charles’ lives are changed forever.As Brian and Charles hits cinemas, WIRED caught up with Earl and cowriter Chris Hayward to talk about optimism, character comedy, and how the pair worked to find the intersection of American Movie and AI.WIRED: David, you've been doing the Brian character for some time, though he's gone through some changes and tweaks over the years. How would you describe where he is in this film emotionally and mentally?
artificial-intelligence	/article/voice-recognition-privacy-speech-changer	The Race to Hide Your Voice	Your voice reveals more about you than you realize. To the human ear, your voice can instantly give away your mood, for example—it’s easy to tell if you’re excited or upset. But machines can learn a lot more: inferring your age, gender, ethnicity, socio-economic status, health conditions, and beyond. Researchers have even been able to generate images of faces based on the information contained in individuals’ voice data.As machines become better at understanding you through your voice, companies are cashing in. Voice recognition systems—from Siri and Alexa to those using your voice as your password—have proliferated in recent years as artificial intelligence and machine learning have unlocked the ability to understand not just what you are saying but who you are. Big Voice may be a $20 billion industry within a few years. And as the market grows, privacy-focused researchers are increasingly searching for ways to protect people from having their voice data used against them.Vocal ThreatsBoth the words you say and how you say them can be used to identify you, says Emmanuel Vincent, a senior research scientist specializing in voice technologies at France’s National Institute for Research in Digital Science and Technology (Inria), but this is only the beginning. “You will also find other pieces of information about your emotions or your medical condition,” Vincent says.“These additional pieces of information help build a more complete profile—then this would be used for all sorts of targeted advertisements,” Vincent says. As well as your voice data potentially feeding into the vast realm of data used to show you online ads, there’s also the risk that hackers could access the location where your voice data is stored and use it to impersonate you. A small number of these cloning incidents have already happened, proving the value your voice holds. Simple robocall scams have also recorded people saying “yes” to use the confirmation in payment scams.Last year, TikTok changed its privacy policies and started collecting the voiceprints—a loose term for the data your voice contains—of people in the US alongside other biometric data, such as your faceprint. More broadly, call centers are using AI to analyze people’s “behavior and emotion” during phone calls and evaluate the “tone, pace, and pitch of every single word” to develop profiles of people and increase sales. “We’re almost in a situation where the systems to recognize who you are and link everything together exist, but the protection is not there—and it’s still quite far away from being readily usable,” says Henry Turner, who researched the security of voice systems at the University of Oxford.Hidden MeaningYour voice is produced through a complex process involving the lungs and your voice box, throat, nose, mouth, and sinuses. More than a hundred muscles are activated when you speak, says Rébecca Kleinberger, a voice researcher at the MIT Media Lab. “It's also very much the brain,” Kleinberger says. Researchers are experimenting with four ways to enhance privacy for your voice, says Natalia Tomashenko, a researcher at Avignon University, France, who has been studying voice and is the first author of a research paper on the results of a voice privacy engineering challenge. None of the methods are perfect, but they are being explored as possible ways to boost privacy in the infrastructure processing your voice data.First is obfuscation, which tries to completely hide who the speaker is. Think of a Hollywood depiction of a hacker totally distorting their voice over a phone call as they explain a devilish plot or ransom (or hacktivist collective Anonymous’s promotional videos). Simple voice-changing hardware allows anyone to quickly change the sound of their voice. More advanced speech-to-text-to-speech systems can transcribe what you’re saying and then reverse the process and say it in a new voice.Second, Tomashenko says, researchers are looking at distributed and federated learning—where your data doesn’t leave your device but machine learning models still learn to recognize speech by sharing their training with a bigger system. Another approach involves building encrypted infrastructure to protect people’s voices from snooping. However, most efforts are focused on voice anonymization.Anonymization attempts to keep your voice sounding human while stripping out as much of the information that could be used to identify you as possible. Speech anonymization efforts currently involve two separate strands: anonymizing the content of what someone is saying by deleting or replacing any sensitive words in files before they are saved and anonymizing the voice itself. Most voice anonymization efforts at the moment involve passing someone’s voice through experimental software that will change some of the parameters in the voice signal to make it sound different. This can involve altering the pitch, replacing segments of speech with information from other voices, and synthesizing the final output.
artificial-intelligence	/article/europe-police-facial-recognition-prum	Europe Is Building a Huge International Facial Recognition System	For the past 15 years, police forces searching for criminals in Europe have been able to share fingerprints, DNA data, and details of vehicle owners with each other. If officials in France suspect someone they are looking for is in Spain, they can ask Spanish authorities to check fingerprints against their database. Now European lawmakers are set to include millions of photos of people’s faces in this system—and allow facial recognition to be used on an unprecedented scale.The expansion of facial recognition across Europe is included in wider plans to “modernize” policing across the continent, and it comes under the Prüm II data-sharing proposals. The details were first announced in December, but criticism from European data regulators has gotten louder in recent weeks, as the full impact of the plans have been understood.“What you are creating is the most extensive biometric surveillance infrastructure that I think we will ever have seen in the world,” says Ella Jakubowska, a policy adviser at the civil rights NGO European Digital Rights (EDRi). Documents obtained by EDRi under freedom of information laws and shared with WIRED reveal how nations pushed for facial recognition to be included in the international policing agreement.The first iteration of Prüm was signed by seven European countries—Belgium, Germany, Spain, France, Luxembourg, the Netherlands, and Austria—back in 2005 and allows nations to share data to tackle international crime. Since Prüm was introduced, take-up by Europe's 27 countries has been mixed.Prüm II plans to significantly expand the amount of information that can be shared, potentially including photos and information from driving licenses. The proposals from the European Commission also say police will have greater “automated” access to information that’s shared. Lawmakers say this means police across Europe will be able to cooperate closely, and the European law enforcement agency Europol will have a “stronger role.”The inclusion of facial images and the ability to run facial recognition algorithms against them are among the biggest planned changes in Prüm II. Facial recognition technology has faced significant pushback in recent years as police forces have increasingly adopted it, and it has misidentified people and derailed lives. Dozens of cities in the US have gone as far as banning police forces from using the technology. The EU is debating a ban on the police use of facial recognition in public places as part of its AI Act.However, Prüm II allows the use of retrospective facial recognition. This means police forces can compare still images from CCTV cameras, photos from social media, or those on a victim’s phone against mug shots held on a police database. The technology is different from live facial recognition systems, which are often connected to cameras in public spaces; these have faced the most criticism.The European proposals allow a nation to compare a photo against the databases of other countries and find out if there are matches—essentially creating one of the largest facial recognition systems in existence. One document obtained by EDRi says the number of potential matches could range from between 10 and 100 faces, although this figure needs to be finalized by politicians. A European Commission spokesperson says that a human will review the potential matches and decide if any of them are correct, before any further action is taken. “In a significant number of cases, a facial image of a suspect is available,” France’s interior minister said in the documents. It claimed to have solved burglary and child sexual abuse cases using its facial recongition system.The Prüm II documents, dated from April 2021, when the plans were first being discussed, show the huge number of face photos that countries hold. Hungary has 30 million photos, Italy 17 million, France 6 million, and Germany 5.5 million, the documents show. These images can include suspects, those convicted of crimes, asylum seekers, and “unidentified dead bodies,” and they come from multiple sources in each country.
artificial-intelligence	/article/deepmind-ai-nuclear-fusion	DeepMind Has Trained an AI to Control Nuclear Fusion	"The inside of a tokamak—the doughnut-shaped vessel designed to contain a nuclear fusion reaction—presents a special kind of chaos. Hydrogen atoms are smashed together at unfathomably high temperatures, creating a whirling, roiling plasma that’s hotter than the surface of the sun. Finding smart ways to control and confine that plasma will be key to unlocking the potential of nuclear fusion, which has been mooted as the clean energy source of the future for decades. At this point, the science underlying fusion seems sound, so what remains is an engineering challenge. “We need to be able to heat this matter up and hold it together for long enough for us to take energy out of it,” says Ambrogio Fasoli, director of the Swiss Plasma Center at École Polytechnique Fédérale de Lausanne in Switzerland.That’s where DeepMind comes in. The artificial intelligence firm, backed by Google parent company Alphabet, has previously turned its hand to video games and protein folding, and has been working on a joint research project with the Swiss Plasma Center to develop an AI for controlling a nuclear fusion reaction.In stars, which are also powered by fusion, the sheer gravitational mass is enough to pull hydrogen atoms together and overcome their opposing charges. On Earth, scientists instead use powerful magnetic coils to confine the nuclear fusion reaction, nudging it into the desired position and shaping it like a potter manipulating clay on a wheel. The coils have to be carefully controlled to prevent the plasma from touching the sides of the vessel: this can damage the walls and slow down the fusion reaction. (There’s little risk of an explosion as the fusion reaction cannot survive without magnetic confinement).But every time researchers want to change the configuration of the plasma and try out different shapes that may yield more power or a cleaner plasma, it necessitates a huge amount of engineering and design work. Conventional systems are computer-controlled and based on models and careful simulations, but they are, Fasoli says, “complex and not always necessarily optimized.”DeepMind has developed an AI that can control the plasma autonomously. A paper published in the journal Nature describes how researchers from the two groups taught a deep reinforcement learning system to control the 19 magnetic coils inside TCV, the variable-configuration tokamak at the Swiss Plasma Center, which is used to carry out research that will inform the design of bigger fusion reactors in the future. “AI, and specifically reinforcement learning, is particularly well suited to the complex problems presented by controlling plasma in a tokamak,” says Martin Riedmiller, control team lead at DeepMind.The neural network—a type of AI setup designed to mimic the architecture of the human brain—was initially trained in a simulation. It started by observing how changing the settings on each of the 19 coils affected the shape of the plasma inside the vessel. Then it was given different shapes to try to re-create in the plasma. These included a D-shaped cross section close to what will be used inside ITER (formerly the International Thermonuclear Experimental Reactor), the large-scale experimental tokamak under construction in France, and a snowflake configuration that could help dissipate the intense heat of the reaction more evenly around the vessel.DeepMind's neural network was able to manipulate the plasma inside a fusion reactor into a number of different shapes that fusion researchers have been exploring.
Illustration: DeepMind & SPC/EPFL DeepMind’s AI was able to autonomously figure out how to create these shapes by manipulating the magnetic coils in the right way—both in the simulation and when the scientists ran the same experiments for real inside the TCV tokamak to validate the simulation. It represents a “significant step,” says Fasoli, one that could influence the design of future tokamaks or even speed up the path to viable fusion reactors. “It’s a very positive result,” says Yasmin Andrew, a fusion specialist at Imperial College London, who was not involved in the research. “It will be interesting to see if they can transfer the technology to a larger tokamak.”Fusion offered a particular challenge to DeepMind’s scientists because the process is both complex and continuous. Unlike a turn-based game like Go, which the company has famously conquered with its AlphaGo AI, the state of a plasma constantly changes. And to make things even harder, it can’t be continuously measured. It is what AI researchers call an “under–observed system.”“Sometimes algorithms which are good at these discrete problems struggle with such continuous problems,” says Jonas Buchli, a research scientist at DeepMind. “This was a really big step forward for our algorithm, because we could show that this is doable. And we think this is definitely a very, very complex problem to be solved. It is a different kind of complexity than what you have in games.”This isn’t the first time artificial intelligence has been used to try to control nuclear fusion. Since 2014, Google has been working with California-based fusion company TAE Technologies to apply machine learning to a different type of fusion reactor—speeding up the analysis of experimental data. Research at the Joint European Torus (JET) fusion project in the UK has used AI to try to predict the behavior of plasma. The concept even appears in fiction: In 2004’s Spider-Man 2, villain Doc Ock creates an AI-powered, brain-controlled exoskeleton to control his experimental fusion reactor, which works great until the AI takes over his mind and starts killing people."
artificial-intelligence	/article/deep-learning-versus-human-intelligence	Why Computers Don’t Need to Match Human Intelligence	Speech and language are central to human intelligence, communication, and cognitive processes. Understanding natural language is often viewed as the greatest AI challenge—one that, if solved, could take machines much closer to human intelligence. In 2019, Microsoft and Alibaba announced that they had built enhancements to a Google technology that beat humans in a natural language processing (NLP) task called reading comprehension.  This news was somewhat obscure, but I considered this a major breakthrough because I remembered what had happened four years earlier.In 2015, researchers from Microsoft and Google developed systems based on Geoff Hinton’s and Yann Lecun’s inventions that beat humans in image recognition.  I predicted at the time that computer vision applications would blossom, and my firm made investments in about a dozen companies building computer-vision applications or products. Today, these products are being deployed in retail, manufacturing, logistics, health care, and transportation. Those investments are now worth over $20 billion.So in 2019, when I saw the same eclipse of human capabilities in NLP, I anticipated that NLP algorithms would give rise to incredibly accurate speech recognition and machine translation, that will one day power a “universal translator” as depicted in Star Trek.  NLP will also enable brand-new applications, such as a precise question-answering search engine (Larry Page’s grand vision for Google) and targeted content synthesis (making today’s targeted advertising child’s play).  These could be used in financial, health care, marketing, and consumer applications. Since then, we’ve been busy investing in NLP companies. I believe we may see a greater impact from NLP than computer vision.What is the nature of this NLP breakthrough?  It’s a technology called self-supervised learning.  Prior NLP algorithms required gathering data and painstaking tuning for each domain (like Amazon Alexa, or a customer service chatbot for a bank), which is costly and error-prone. But self-supervised training works on essentially all the data in the world, creating a giant model that may have up to several trillion parameters.  This giant model is trained without human supervision—an AI “self-trains” by figuring out the structure of the language all by itself. Then, when you have some data for a particular domain, you can fine-tune the giant model to that domain and use it for things like machine translation, question answering, and natural dialog. The fine-tuning will selectively take parts of the giant model, and it requires very little adjustment.  This is somewhat akin to how humans first learn a language and then, on that basis, learn specific knowledge or courses. Since the 2019 breakthrough, we have seen giant NLP models increase rapidly in size (about 10 times per year), with corresponding performance improvements.  We have also seen amazing demonstrations—such as GPT-3, which could write in anybody’s style (such as Dr. Seuss-style), or Google Lambda, which converses naturally in human speech, or a Chinese startup called Langboat that generates marketing collateral differently for each person.Are we about to crack the natural language problem? Skeptics say these algorithms are merely memorizing the whole world’s data, and are recalling subsets in a clever way, but have no understanding and are not truly intelligent. Central to human intelligence are the abilities to reason, plan, and be creative. One critique of deep-learning-based systems runs like this: “They will never have a sense of humor. They will never be able to appreciate art, or beauty, or love. They will never feel lonely. They will never have empathy for other people, for animals, or the environment. They will never enjoy music or fall in love, or cry at the drop of a hat.”  Makes sense, right? As it turns out, the quotation above was written by GPT-3. Does the technology’s ability to make such an accurate critique contradict the critique itself?
artificial-intelligence	/article/deepfake-nude-abuse	The Biggest Deepfake Abuse Site Is Growing in Disturbing Ways	A deepfake website that generates “nude” images of women using artificial intelligence is spreading its murky tentacles across the web—spawning look-alike services through partner agreements and recruiting new users through a referral system. The expansion efforts have allowed the service to proliferate despite bans placed on its payment infrastructure.The website, which WIRED is not naming to limit its amplification, has existed since last year. It digitally “removes” clothing from non-nude photos to create nonconsensual pornographic deepfakes. Researchers say its output is “hyper-realistic,” and unlike similar abusive platforms, it can generate pornographic images even when the person in the original photo is fully clothed. Previously, similar technologies have only worked with partially clothed photographs.In recent months the website has expanded its services, earning its creator potentially thousands of dollars. The website has made its algorithms available to “partners” through access to its APIs; and two spin-off websites have been created by other people. The original website has been previously reported on, but the extent of its partner programs has not.The website’s “partner program” page says the scheme was created so that the developer behind the system can “focus more” on AI research, provide customers with alternate payment methods, and create localized-language versions of the site. It claims that having a decentralized model lets it avoid “sudden suspension of service, even termination.”This approach does seem to have helped the website avoid being taken offline. According to data from digital intelligence platform Similarweb, the site had more than 50 million visits between January and the end of October this year, making it the biggest of its kind. “Hundreds of thousands” of images have been uploaded on a single day, the creator has claimed on the website. Its audience peaked in August with 6.92 million views, according to SimilarWeb’s data.“This can have real and devastating consequences.”Seyi Akiwowo, Glitch!The site received attention from the Huffington Post and others at around that time as well, leading to its hosting being taken offline and cryptocurrency platform Coinbase appearing to suspend its payment account. Those restrictions slashed visitor numbers in half, down to 3.14 million visitors in October; 13.93 percent of visitors were in the United States. While it has declined in size, its business partners have grown, helping to keep the abusive technology accessible to millions of people. In October, one of the spin-off websites, according to the SimilarWeb data, recorded approximately 830,000 visitors, while the other had almost 300,000. In the months before, both only recorded tens of thousands of visitors. The original website drives much of this additional traffic.The creator of one of these murky spin-off sites says they are paying around $500 to the original website for the ability to create 10,000 nude images. A counter on the partner website claims to have processed 204,522 images from more than 3,000 paying customers. While the other partner website includes the claim that the AI training data set includes more than 1 million images, it is not clear where these images have come from, with the creator of the original website writing online that the service does not store images or use them for training purposes.Recruiting partners is not the only way the website has sustained itself. Hundreds of links for the website’s referral program—where people receive free image-generation tokens every time someone clicks—are also being shared on Twitter, YouTube, Telegram, and specialized pornographic deepfake forums.
business	/article/fact-checkers-ai-chatgpt-misinformation	Fact-Checkers Are Scrambling to Fight Disinformation With AI	Spain’s regional elections are still nearly four months away, but Irene Larraz and her team at Newtral are already braced for impact. Each morning, half of Larraz’s team at the Madrid-based media company sets a schedule of political speeches and debates, preparing to fact-check politicians’ statements. The other half, which debunks disinformation, scans the web for viral falsehoods and works to infiltrate groups spreading lies. Once the May elections are out of the way, a national election has to be called before the end of the year, which will likely prompt a rush of online falsehoods. “It’s going to be quite hard,” Larraz says. “We are already getting prepared.”The proliferation of online misinformation and propaganda has meant an uphill battle for fact-checkers worldwide, who have to sift through and verify vast quantities of information during complex or fast-moving situations, such as the Russian invasion of Ukraine, the Covid-19 pandemic, or election campaigns. That task has become even harder with the advent of chatbots using large language models, such as OpenAI’s ChatGPT, which can produce natural-sounding text at the click of a button, essentially automating the production of misinformation. Faced with this asymmetry, fact-checking organizations are having to build their own AI-driven tools to help automate and accelerate their work. It’s far from a complete solution, but fact-checkers hope these new tools will at least keep the gap between them and their adversaries from widening too fast, at a moment when social media companies are scaling back their own moderation operations.“The race between fact-checkers and those they are checking on is an unequal one,” says Tim Gordon, cofounder of Best Practice AI, an artificial intelligence strategy and governance advisory firm, and a trustee of a UK fact-checking charity.“Fact-checkers are often tiny organizations compared to those producing disinformation,” Gordon says. “And the scale of what generative AI can produce, and the pace at which it can do so, means that this race is only going to get harder.”Newtral began developing its multilingual AI language model, ClaimHunter, in 2020, funded by the profits from its TV wing, which produces a show fact-checking politicians, and documentaries for HBO and Netflix.Using Microsoft’s BERT language model, ClaimHunter’s developers used 10,000 statements to train the system to recognize sentences that appear to include declarations of fact, such as data, numbers, or comparisons. “We were teaching the machine to play the role of a fact-checker,” says Newtral’s chief technology officer, Rubén Míguez.
business	/article/tech-layoffs-signal-the-end-of-the-office-perk	Tech Layoffs Signal the End of the Office Perk	Until last March, Meta employees in New York didn’t have to worry about food, transport, or laundry. There were shuttle buses waiting to take them home at the end of the day, a free dinner service with complementary to-go boxes, and courtesy laundry pickup. “It’s a very pampered place,” says Devi, a software developer at the company’s Manhattan campus, who asked that his name be changed to avoid jeopardizing his future career. In March, as part of a cost-cutting exercise, the laundry service was taken away, and the daily dinner service was pushed back by half an hour—after the last shuttle was scheduled to leave the campus—meaning that workers had to pick between a free meal and a free ride home. There was an uproar, according to Devi.“It was funny seeing a bunch of well-paid tech folks complain about losing free food,” he says. “Some of them had rented apartments in expensive Manhattan neighborhoods since they had dinner sorted at work—they weren’t happy.”Perks, from state-of-the-art gym facilities to private pop concerts to on-site sushi bars, have become integral to the culture at big technology companies. While they may seem excessive at a time of job losses across the industry, employees expect them, and experts say cutting them could have a real impact on companies’ ability to hire and retain in the future. “The problem for these companies that want to keep their megastars happy is that they’ve become used to amazing packages being offered,” says Grace Lordan, associate professor in behavioral science at the London School of Economics. “It can impact the war on talent: The companies offering the best packages will help get the best employees.” Tech companies began offering perks in an age when the boundaries between workers’ professional and personal lives were eroding. But Silicon Valley went further than ping-pong tables. At Facebook, some employees were provided with on-site meditation centers. Apple workers were given fortnightly “Beer Bash” parties, with the occasional surprise performance from a music legend. And, as a reward for a job well done, Googlers were offered “massage credits”—to be redeemed on campus, of course.The idea wasn’t just to keep workers on campus for as long as possible. “Creativity and innovation often emerge in conducive environments—places where people can interact with joy even during their down time,” says Tomas Chamorro-Premuzic, professor of business psychology at University College London. “Many of the raw ingredients that make up the fabric of creative ideas and successful collaboration emerge not during formal meetings, but during informal encounters, like at the cafeteria or volleyball court.”
business	/article/google-meta-big-tech-is-bad-at-firing	Big Tech Is Really Bad at Firing People	For one Google worker it was when the light on the card reader outside their New York office flashed red, rather than green. For a staffer at Twitter, it was when their password was changed remotely, and an unusual gray screen showed their company Macbook had been locked. For Zac Bowling, a near-eight-year veteran of Google, it was being logged out of all his devices.Tech companies have laid off tens of thousands of workers over the past few months in an industry-wide downsizing that executives have blamed on overhiring during the pandemic. Almost without fail, they’ve handled it horribly, with casual brutality and tone deaf displays—such as at Microsoft, who hosted a private Sting concert at Davos the night before firing 10,000 people.The disparity between Big Tech’s high spending and the callous way in which they have let go of their staff has tarnished their reputation as good employers, and reminded staff that their needs are subordinate to those of shareholders. “Finding out via email or auto shut out that you have lost your job is brutal—and it doesn’t have to be that way,” says Gemma Dale, lecturer at Liverpool Business School, and author of a number of books, including on employee well-being and flexible work. “It also totally disconnects with what many of these organizations say about how much they value their people.” Bowling eventually learned that he had been let go from Google via an email two hours after he was logged out of all his work systems on the morning of January 20. His manager had to use LinkedIn to reach him to apologize, because his access to Google Meet and other internal company communication tools had been cut. It was entirely unexpected—Bowling had gotten a new batch of business cards made in December. Others just received, or were expecting, glowing performance reviews but were instead given severance terms. “It caught everybody off guard,” Bowling says. “It didn’t seem like they were going after low performers, or they were going after specific projects. Someone likened it to if someone had a Tommy gun, and they were just shooting from the hip.” People who are still at the company aren’t sure if they’re next. Bowling said that workers who still have access to the company’s systems told him 8,000 names have disappeared from employee rolls. But Google has said it’s letting go of 12,000 people worldwide. “Everybody’s saying goodbye, just in case, because they don’t know if they’re going to get everything cut off,” Bowling says. “It’s killing morale. It was just handled terribly.”
business	/article/gender-labor-recession	The Workforce Is Failing Women. Business Leaders Can Stop It	The past few years have shone a brighter light on women’s experiences at work: We’re exhausted, we’re underpaid, and we’re constantly battling for basic rights. In fact, we’re well in the depths of a “she-cession”: One in three women are looking to downshift their careers or leave the workforce entirely, joining the millions of women who have already exited these past few years. READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.With a global labor shortage and a caregiving crisis continuing to strain workforces, smart leaders will invest in reversing the she-cession by making structural changes in how we work that emphasize flexibility. Failure to do so will push more women to their breaking point, and out of the workplace. But it is not women who are broken, it’s the system. And 2023 will be the year to start fixing it. There’s no question that flexibility matters. When it comes to determining job satisfaction, research by Slack’s Future Forum consortium shows that flexibility ranks second only behind compensation. This is particularly true for parents, especially working mothers. Today, 83 percent of working mums prefer a flexible location model. But, too often, the conversation about flexibility is limited to just the “number of days in the office.” In 2023, the meaning of flexibility will move beyond where you work to when you work. Ninety-five percent of female desk workers want flexibility in their schedules—more choice in how they structure their days aside from the occasional appointment out of the office—and the majority are not getting that option today. With the demand for flexibility clear, and the rate of attrition high, leaders will give employees greater choice in how they work and break away from the traditional, outmoded 9-to-5 model of productivity.This shift to flexibility has numerous benefits: We’re seeing major gains for professional women when it comes to sense of belonging, satisfaction with work, and work-life fluidity. But proximity bias—favoritism for people who work nearby in the office—is a looming risk that leaders must actively negate. Why? Our research shows that women, employees of color, and working mothers are most likely to want to continue to work flexibly, while men, white employees, and non-caregivers are more likely to go back into the office full-time. Left unchecked and without intentional action, disparities in the workplace could deepen, entrenching existing inequities.To combat proximity bias, leaders will become increasingly cognizant of how employee performance is measured during promotion reviews and feedback cycles. Research shows that men are much more likely to receive feedback based on the outcomes they deliver, whereas women’s evaluations are more likely to be rooted in personality traits. In 2023, a growing number of managers will be reskilled to focus on the outcomes that employees are producing instead of outdated measures of work ethic and commitment, like being the “first in and last to leave.” When they get this right, companies will start to see the impact in their ability to attract and retain talent.My hope is that we’re finally ready to build a more equitable, more representative workforce by truly fixing a system that’s always been broken. Growing up, I watched my immigrant mother continually make trade-offs between parenting and working—and because of the financial needs of our broader family, work often won. I remember how painful those choices were for her, and at the end of her 40-year career, her advice to me was: “Regardless of how hard you work, trying [to break the glass ceiling] is not worth it.” The past two years have proven that change is possible, as millions of people fundamentally reimagined how they work. But to make systemic change, leaders must redesign how they hire, evaluate, and promote women. And the time to change the system is now.
business	/article/amazon-strike-uk-pay	The Rebellion Amazon Can No Longer Ignore	The last time Amazon employee Darren Westwood was on strike, Amazon didn’t exist. He was working as a train guard and it was the 1980s—the only other time in recent British history when inflation surged past 9 percent.In the early hours of January 25, he’s on the picket line again outside Amazon’s giant Coventry warehouse, where he gets paid £10.46 ($12.90) per hour to work alongside a fleet of robots. Westwood, a member of the UK’s GMB Union, is here to campaign for higher pay. “When we started this protest, I think inflation was at 6 percent. Now we’re at 10.5 percent and people can't cope,” he says. “It just doesn’t feel fair. We’re doing 40 hours a week, stood up for 10 hours a day. And I’m still struggling to pay my bills.” Westwood is among a group of Amazon day shift employees, union representatives, and TV cameras waiting in nervous silence to see whether workers on the night shift will be bold enough to walk away from their workstations. A few minutes after midnight, four figures emerge from the mist and the crowd waiting for them erupts into cheers and applause. Others follow, walking in small groups. These are the first Amazon workers to officially go on strike in the UK. Among them is Mal (who declines to give his surname for reasons of privacy). “We are trying to fight for a pay rise,” he says. Thaddeus, who has worked at Amazon for three years, agrees. “Hopefully this strike will have a domino effect,” says Westwood, who is hoping other warehouses will follow Coventry’s example. The Coventry strike is expected to last for 24 hours, but organizers could announce further dates. 
business	/article/teslas-problems-elon-musk-twitter	Tesla’s Problems Go Way Beyond Elon Musk	For now, Alex Lagetko is holding on to his Tesla stocks. The founder of hedge fund VSO Capital Management in New York, Lagetko says his stake in the company was worth $46 million in November 2021, when shares in the electric carmaker peaked at $415. Since then, they have plunged 72 percent, as investors worry about waning demand, falling production and price cuts in China, labor shortages in Europe, and, of course, the long-term impact of CEO Elon Musk’s $44 billion acquisition of Twitter. After announcing his plans to buy the platform in April, Musk financed his acquisition with $13 billion in loans and $33 billion in cash, roughly $23 billion of which was raised by selling shares in Tesla. “Many investors, particularly retail, who invested disproportionately large sums of their wealth largely on the basis of trust in Musk over many years were very quickly burned in the months following the acquisition,” Lagetko says, “particularly in December as he sold more stock, presumably to fund losses at Twitter.”Lagetko trimmed his exposure in early 2022 due to concerns over Tesla's governance. But he is worried that the leveraged buyout of Twitter has left Tesla vulnerable, as interest payments on the debt Musk took on to fund the takeover come due at the same time as the social media company’s revenues have slumped.But Tesla stock was already falling in April 2022, when Musk launched his bid for Twitter, and analysts say that the carmaker’s challenges run deeper than its exposure to the struggling social media platform. Tesla and its CEO have alienated its core customers while its limited designs and high prices make it vulnerable to competition from legacy automakers, who have rushed into the EV market with options that Musk’s company will struggle to match.Prior to 2020, Tesla was essentially “playing against a B team in a soccer match,” says Matthias Schmidt, an independent analyst in Berlin who tracks electric car sales in Europe. But that changed in 2020, as “the opposition started rolling out some of their A squad players.”In 2023, Tesla is due to release its long-awaited Cybertruck, a blocky, angular SUV first announced in 2019. It is the first new launch of a consumer vehicle by the company since 2020. A promised two-seater sports car is still years away, and the Models S, X, Y, and 3, once seen as space-age dynamos, are now “long in the tooth,” says Mark Barrott, an automotive analyst at consultancy Plante Moran. Most auto companies refresh their looks every three to five years—Tesla’s Model S is now more than 10 years old.
business	/article/landlords-rentals-decentraland-metaverse	Metaverse Landlords Are Creating a New Class System	For the modest price of 10,000 MANA tokens (or $7,000) per day, anyone can rent land parcel 27,87 in Decentraland, a 3D virtual world that runs on the Ethereum blockchain. Renting the plot would give the tenant the right to build anything they please—a shop, an event space, an art installation, or whatever else—to host friendly passersby. But the real winner would be their landlord, who goes by the name Beatrix#7239, their virtual pockets bulging with cash. Not every property is as expensive as parcel 27,87, which is located in the center of the world map, close to where people first spawn into Decentraland. And no one has taken up the rental offer on these terms yet. However, a market for leasing virtual real estate is beginning to take shape, creating a new source of income for virtual landowners who buy up attractive spaces in the metaverse.In the past nine months, brands like Mastercard and Heineken have rented plots for one-off events or product showcases and, in December, Decentraland released tools that allow anyone to rent virtual land.The objective was to democratize access to the virtual world, explains Nico Rajco, who led the development of the rentals feature for Decentraland. Everybody benefits, he says, because renting gives new users an ideal “jumping-off point” and landowners can earn a passive income. But the rental system is also subtly changing the social fabric of the virtual world, dividing people into those who have and those who have not.When Decentraland launched in 2017, people were given the chance to purchase the ownership rights to 90,601 parcels of virtual land, each represented on the Ethereum blockchain by a non-fungible token (NFT). At the time, plots were sold for roughly $20 apiece, but by the end of 2021—at the height of the NFT boom—land was routinely changing hands for tens of thousands of dollars. One company, Metaverse Group, purchased a single Decentraland plot for $2.4 million.In line with the slump in the crypto market, demand for virtual real estate has cooled off, leaving landowners looking for new ways to profit from their investments. The new Decentraland rentals system gives them a way to do just that.The earliest adopters are mostly brands and artists that want to host events or put on shows in Decentraland, with tenancies ranging in duration from a single day to multiple months. The appetite for renting virtual real estate also remains small; there are currently around 300 plots listed on the marketplace and only 40 are occupied by tenants.
business	/article/ai-labor-interns	Infinite AI Interns for Everybody	Robert Solow, the Nobel Prize–winning economist, famously said in 1987 that you can see the computer revolution everywhere but in the productivity statistics. I predict 2023 is the year that finally changes, thanks to artificial intelligence. By the end of 2023, AI will be fast becoming one of the most important factors of production in the global economy.READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.It’s true that the history of AI is largely a history of disappointment: hype followed by “AI winters,” in which both talent and funding abandon the discipline. But this time, thanks to the deep learning revolution, it really is different. In 2023, we’ll see ordinary people, everywhere, enjoy the power of AI at their fingertips. What might this look like? Let’s say you need to create a marketing brochure for a new geography that your company is entering. Trained on the data set of all the material your firm has ever created, your AI assistant creates three options for you within minutes—each beautifully written and illustrated. They’re not perfect, yet, but what used to be a weeklong project becomes the work of a couple of hours.That’s just an example, but the critical point is that AI is on the cusp of giving us all superpowers. You will have the ability to generate an email or memo in your own voice (or anyone else’s for that matter) in seconds. You will be able to create photorealistic art—or even video—with a few bullet-points of instructions. You will be able to answer arbitrary scientific questions by having the AI “read” entire corpuses of academic literature. You will be able to delegate your bookkeeping and accounts to an AI algorithm. Some of this innovation will come from the usual suspects, like DeepMind and OpenAI. OpenAI has already released GPT-3 (a program which generates natural language) and DALL-E (which creates images from text) in beta, but we can expect these tools to be widely available soon. Excitingly, though, there’s also a new generation of startups that are demonstrating that you don’t need a billion-dollar budget to get to the cutting edge of AI. Take Midjourney or Stability AI, applications which produce results that rival DALL-E, or Causaly (disclosure: I’m an investor), which allows scientists to find new causal relationships in life sciences with natural language questions. Then there is a growing list of new AI startups with impressive backers and more general ambitions, like Anthropic (an AI safety and research firm), Conjecture (which seeks to keep damaging factors such as racial bias out of AI), and Keen Technologies, which was founded by computer science legend John Carmack.This is not a prediction about artificial general intelligence, still less about AI “replacing” humans. It’s hard to overstate, though, the impact of freeing up billions of hours of human labor and making creativity and knowledge too cheap to meter. I fully expect this to unleash a huge wave of entrepreneurship. Just as the advent of the internet gave every startup a vastly scalable distribution engine, the era of AI superpowers will give every startup a vastly scalable production engine. Tech analyst Benedict Evans said in 2018 that one way of thinking about AI is that it it’s like giving every company infinite interns. In 2023, those interns will be world-class copywriters, illustrators, and more—perhaps scientists, data analysts, or even negotiators. What would you build with a million such “interns” in the cloud, available on demand, 24/7, and at close to zero marginal cost? In 2023, we can expect thousands of entrepreneurs to show us.
business	/article/the-collapse-of-britishvolt	The Collapse of the UK’s Electric Vehicle Champion	Britishvolt was meant to be the UK’s answer to Tesla. By 2024, it was supposed to be producing hundreds of thousands of lithium-ion batteries a year for the British automotive sector, and driving an industrial renaissance for the economically deprived northeast of the country. Since its launch in 2019, the company had amassed nearly $2.5 billion in funding promises, including £100 million ($123 million) from the UK government, and preliminary deals to supply batteries to Aston Martin and Lotus.But barely nine months after it broke ground on its “gigafactory” in Northumberland in August 2022, Britishvolt has gone into administration, the equivalent of Chapter 11 bankruptcy in the US. The majority of its 232 staff are being made redundant.It’s a chaotic end to a startup that had enormous ambitions and was billed as a cornerstone of the UK’s electric vehicle industry. Its collapse has left staff, analysts, and policymakers scrambling to understand how it could have gone so wrong so fast, and what it means for the future of the UK’s battery business.“In some ways, I am surprised,” one former employee, who left the company in December, tells WIRED, speaking on condition of anonymity. “The business had ambitious plans, and from the people I worked with, the knowledge and experience to execute them.”Britishvolt was founded by Swedish entrepreneurs Orral Nadjari and Lars Carlstrom in 2019. Neither had experience in the electric vehicle space, but they approached the endeavor more like startup founders than industrialists by bootstrapping, and making bold promises of future growth.“It was always going to be difficult,” says David Bailey, professor of business economics at Birmingham Business School in the UK. “They didn't have a track record in technology development. They hadn't secured all the funding needed to build out the factory for about £3.8 billion. And they didn't have any big customers.” But the company’s vision supported the UK government’s narrative of “leveling up”—supporting the development of struggling, often postindustrial, areas of the country. Britishvolt’s factory in the northeast promised to create 3,000 new jobs, with another 5,000 in its supply chain. Announcing that the government would provide the company with funding in 2022, then-prime minister Boris Johnson called the facility “a strong testament to the skilled workers of the North East and the UK’s place at the helm of the global green industrial revolution.”
business	/article/twitter-sudden-death-vaccine-conspiracies	Twitter Is a Megaphone for ‘Sudden Death’ Vaccine Conspiracies	When British radio DJ Tim Gough passed away suddenly during a broadcast in October 2022, his friend and colleague James Hazell barely had time to mourn before the trolling began. “They didn’t even give him time to go cold. They were straight on it with some vile messages,” Hazell says.Anti-vaccine conspiracy theorists seized upon Gough’s death, reportedly from a suspected heart attack, and turned his Twitter and Instagram feeds into a storm of disinformation and abuse. “Don’t worry. Safe and very very effective. Perfect for euthanasia also!!!! [sic],” one Twitter user posted. “Death vax,” wrote another. Gough’s accounts, and the Twitter feed of GenX Radio in Suffolk, UK, where he and Hazell worked, were “besieged with abuse,” Hazell says. “They didn’t seem to care about the actual situation of a human dying.”Gough’s is just one of dozens of sudden deaths and medical emergencies that have been exploited by anti-vaccine campaigners, who claim—without evidence—that Covid shots are to blame. It is a tactic they have used before, but analysis by misinformation experts shows that Twitter, which has stopped policing Covid-19 misinformation and restored thousands of previously banned accounts, has helped supercharge the narrative since Elon Musk took over the platform in October 2022. “It has opened the floodgates for conspiracy theorizing and misinformation,” says Timothy Graham, a misinformation expert at the Queensland University of Technology (QUT) in Australia.Twitter did not respond to WIRED’s request for comment. The company reportedly no longer has a media team.In recent months, conspiracy theorists have gravitated toward the news of several high-profile deaths, including that of singer Terry Hall, from British ska band The Specials, in December. Illnesses that have been baselessly blamed on the vaccine include a suspected heart attack—in fact, a panic attack— suffered by musician Rod Stewart’s 11-year-old son, and an eye condition that hospitalized singer Tom Fletcher, from the pop group McFly. In January 2023, anti-vaxxers claimed without basis that the death of musician Lisa-Marie Presley, from a suspected heart attack, was due to her having taken the vaccine.In the US, NFL player Damar Hamlin’s mid-game collapse after a cardiac arrest in January prompted a tsunami of conspiratorial claims attributing his illness to Covid-vaccine-induced myocarditis. While some vaccines have been found to cause inflammation of the heart, experts say cases are rare and usually short-lived, and Covid itself is more likely to cause myocarditis than the vaccine. Studies also indicate that cardiac arrest was a leading cause of unexplained deaths among athletes well before the vaccine rollouts. Tests to determine the cause of Hamlin’s cardiac arrest are reportedly ongoing.
business	/article/heathrow-radioactive-cargo-screening	How Airports Catch Illicit Radioactive Cargo	It was just another package among millions flowing through the Heathrow Airport system. Except this one was radioactive. On December 29, 2022, a detector at the London airport flagged the package, and staff took action to isolate it. They soon found out that it contained uranium—a naturally occurring element that, after a complex process of enrichment, can be used in nuclear reactors and weapons.The uranium was found among scrap metal in a shipment from Pakistan destined for a UK address associated with an Iranian business, according to reports. The Metropolitan Police’s Counter Terrorism Command branch is now investigating. Pakistan’s foreign ministry has denied that the uranium originated in the country.What you might not realize is that detections of undeclared radioactive material at transport hubs and ports of entry happen multiple times every year in the United Kingdom alone. All over the world, security teams screen for radioactive material on the move. This monitoring takes many forms, including covert detectors hidden in the walls at airports that silently scan passengers. Customs officials wave handheld radiation-sniffing devices over boxes. And drones, loaded with sensors, can fly across wide areas while searching for lost radioactive objects.Even so, some potentially harmful material can slip through the net, as the uranium did—until it got to Heathrow.“I want to reassure the public that the amount of contaminated material was extremely small and has been assessed by experts as posing no threat to the public,” Commander Richard Smith of London’s Metropolitan Police said in a statement. He added that the uranium did not appear to be linked to any direct threat. No arrests have been made so far.The uranium almost certainly posed no danger, says Bahram Ghiassee of the Henry Jackson Society, a think tank that focuses on anti-extremism. “Uranium in its natural form, or enriched, poses very little threat to public health,” he explains, noting that it is a relatively weak radioactive material.Ghiassee, who published a report last year on the threat of radiological terrorism, also criticizes suggestions in some news coverage that the uranium found at Heathrow could have been intended for use in a dirty bomb: “For dirty bombs, you need highly radioactive material … and uranium is not suitable at all.”
business	/article/startup-tailoring-sojo	On-Demand Tailoring Brings the Gig Economy to Your Wardrobe	It started with a charity shop off London’s Portobello Road, and the perfect pinstripe suit. Well, almost perfect. “I totally loved it, but it didn’t fit me. So I had the idea for building an app,” explains Josephine Philips, the founder of Sojo, a startup that wants to bring tailoring “into the modern age.”Nicknamed “the Deliveroo of fashion repairs,” Sojo was launched in January 2021, and connects users with nearby seamsters while facilitating the pickup and return of clothes using a network of couriers. Independent seamsters register on the app and set their own price for their work, from fixing holes to altering sizes, with Sojo taking a 30 percent fee. That very same pinstripe suit ended up being one of the app’s first orders.“I experienced going to a tailor, and it was so archaic, it was really backward,” says Philips. “It's not an activity that’s common, and we want to make it common. We want every young person to be engaged with repairs and alterations.” It’s an issue made all the worse by the fact that two thirds of fixable clothes are thrown away.Eighteen months after launch, Sojo is a different beast, fresh from a new $2.4 million funding round, a partnership with Scandinavian fashion brand Ganni, and a hiring push that should see it reach 16 staff. It’s also been a seismic change for Philips. The 24-year-old started working on Sojo full-time straight after graduating from university—her only previous jobs being as a waitress and as a summer intern at second-hand clothing exchange Depop. For those first few months, Sojo was a one-woman show, powered mostly by a mixture of overtime and youthful passion to change the “culture of waste” and “exploitation” that defines the fast fashion industry, from which Philips built up her initial, limited network of couriers and seamsters.“That youth meant I saw the way the system was working and was like, ‘I can actually change that’ … That kind of outlook was definitely a superpower,” says Philips. “But there was a lot going on. Never having done something like this before meant I was learning and doing simultaneously.”As a Black female founder, Philips found herself in an industry where women-led startups account for only 2.8 percent of VC funding. In fact, according to one report, between 2009 and 2019, only one Black female founder in the UK raised any Series A funding at all. “Everyone knows what the venture capital space is for under-represented founders … The numbers speak for themselves,” Philips says, explaining she would regularly get rejected by investors, only to see white male counterparts with little more than “a PowerPoint” making pitches and “getting millions straight off the bat.”Eventually, Sojo was able to secure backers, initially through an angel round with an array of big-name investors, including Depop founder Simon Beckerman. The latest Series A round was led by female-directed VC firm CapitalT.
business	/article/bahamas-ftx-crypto-party	FTX Has Wrecked the Crypto Party in Paradise	The Bahamas, best known for its sun, sand, and crystal waters, is also a paradise for crypto companies. Or at least it was, until crypto exchange FTX made the island of New Providence the setting for a historic crypto collapse in early November. Bahamas-headquartered FTX declared bankruptcy on November 11, and founder Sam Bankman-Fried retreated into hiding. The exchange’s collapse took with it hundreds of millions of dollars in customer funds. The feeling in crypto circles now, says Nicholas Rees, cofounder of Bahamas-based payments firm Kanoo Pays, is of “complete and utter shock.”As other senior FTX employees fled the country, they were replaced by a throng of reporters and crypto influencers heading in the opposite direction, hoping to locate the disgraced crypto wunderkind.Bankman-Fried was ultimately arrested at his $40 million penthouse by Bahamian police on December 12 under the instruction of US law enforcement. He has since been extradited to the US, and on January 3 pleaded not guilty to eight criminal charges, including wire fraud and conspiracy to commit securities and commodities fraud.While Bankman-Fried awaits his trial, penciled for October 2023, members of the Bahamas’ crypto scene are left to pick up the pieces, their reputations impacted by proximity.By virtue of its size and standing, says Rees, FTX’s tendrils extended into many corners of Nassau, the capital city—whether through charitable donations, corporate deals, or events that brought custom to the doors of local businesses. The crypto exchange also cohosted an invite-only conference in July last year, boasting a roster of speakers that included Bill Clinton, Tony Blair, and football player Tom Brady.The Kanoo Innovation Hub, a startup accelerator launched by Kanoo Pays, was mere days away from announcing a partnership with FTX when the scandal broke. Rees claims FTX intended to create a way for accelerator participants to tap into the $100 million pool of capital already set aside for local investments. (FTX did not respond to a request for confirmation of the agreement.)Although the survival of the Innovation Hub is not contingent on FTX funding, Rees says the collaboration promised to take the scheme “to another level,” providing a leg up to founders from the Caribbean.Worse, Rees explains, the collapse of FTX created an employment vacuum that deprived Bahamians of both their current jobs and potential career opportunities. “The saddest part for us, outside the millions of people that lost money,” he says, “is that some of our countrymen would have received the job of a lifetime, but it was pulled out from under them.”
business	/article/getir-europe-delivery-wars	As Gig Economy Companies Flee Europe, Getir Is Taking Over	Five years ago, investors wouldn’t return Nazim Salur’s calls. Now his company, Getir, is the biggest rapid grocery delivery company in Europe. After the Turkish startup acquired its German rival Gorillas last month, the company was valued at $8.8 billion.Getir first expanded into Europe via London in 2021, when a post-pandemic gold rush for instant groceries was in full swing. Investors were convinced that lockdown habits would stick and consumers would continue to demand grocery deliveries direct to their homes. Since 2020, investors have flooded the global sector with more than $5 billion in funding. Those billions funded the dramatic expansion of an industry promising a new era of ultimate convenience: groceries on your doorstep in 10 minutes. In Europe alone, companies launched between 2020 and 2021 included Gorillas, Weezy, Blok, Dija, Fancy, and Cajoo.In a delivery app reckoning, all of those companies have since disappeared or been absorbed by Europe’s three major players: Getir, Flink, and GoPuff. Since Getir swallowed Gorillas in December, the company’s yellow and purple mopeds can be found on roads across seven European countries. Its next largest competitor, Germany’s Flink, is active in three. The American competition, GoPuff, has recently downsized and now only operates in France and Britain. Getir has received funding from Abu Dhabi state investor Mubadala and investment firms Sequoia and Tiger Global to fuel its growth.   The company’s rise from London to Europe’s biggest instant grocery provider is down to Getir’s experience in its home market, says general manager in Europe, Turancan Salur. “We are the pioneers of the sector,” he says. Getir might be new in Europe, but it’s been operating in Turkey for eight years and claims to already be profitable in Istanbul. As a private company, Getir does not publish financial reports. “We have a lot of experience under our belt there and we’ve navigated our fair share of difficult situations and economic difficulties,” says Salur.  While Europe’s newcomers were wrestling with IT problems linked to logistics management, he says, Getir already had custom-made fixes ready to go. “We basically had a preview into the future, whereas our competitors didn’t.”Getir’s dominance is reflected in number of downloads. The company’s app has been downloaded on Android phones 28 million times worldwide, according to AppRadar data that does not count iPhone installs. That figure far eclipses downloads of GoPuff’s app, which has been installed 5.4 million times. And Getir is not only winning over consumers—couriers are also switching to the company. “From my personal experience, Getir is so much better than being fully dependent on Deliveroo or UberEats,” says Ian Morrison, a courier in London who has been working for Getir in London since June 2021. He gets paid £11.05 ($13) per hour, and receives holiday and sick pay. The company provides him with an electric moped to ride during his shifts and covers his insurance.
business	/article/labor-employment-skills	Workers Shuffling Jobs Want a Skills-First Labor Market	In the spring of 2021, the world started opening up again, and we saw an unprecedented amount of movement in the global labor market. It was a moment we called the Great Reshuffle, where employees were rethinking not only how and where they worked, but why—and switching jobs at historic rates. Today, we’re emerging from the Great Reshuffle, and we’re seeing the rate of LinkedIn members changing jobs globally flatline for the first time since March 2021. READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.Now, the word of the day among leaders and companies is uncertainty. We’ve moved from slower, more predictable ebbs and flows to ongoing, persistent disruption as the norm. This presents a massive challenge, but it can also be an opportunity. The leaders and organizations that are adaptive will win. You can wait out the storm only to get hit with the next one, or you can change before you have to and avoid playing catch-up every time a new set of circumstances arises.  Nowhere is the need for adaptive leadership more urgent than when it comes to creating an agile workforce. During the Great Reshuffle, employers were relatively nimble when it came to adopting remote and hybrid work, flipping what was once a niche offering and making it the norm for many sectors. Yet when it comes to the most fundamental asset a company has—its people—we’re still vastly under-innovating and relying on outdated ways to find, retain, and grow talent. The new way forward for building a more equitable and efficient talent marketplace is to shift to a skills-first approach. This is not a novel concept, but it’s one that has lived on the outskirts for far too long. For decades, hiring was primarily based on the degree you'd earned, the jobs you had, the people you knew. This resulted in less agility for employers and lost opportunities for qualified candidates. The world we now live in demands alternative, flexible, and always-accessible paths to well-paying jobs. I believe that change will come through a skills-based approach to opportunity.LinkedIn data suggests that both employees and employers are starting to use skills as a shared language in the job search. More than 40 percent of hirers are now explicitly using skills to screen and search for candidates on LinkedIn. This skills-based approach shouldn’t just stop there. Our recent Global Talent Trends report shows that organizations that excel at internal mobility are able to retain employees for 5.4 years on average, nearly twice as long as those that struggle with it, where the average retention span is less than three years. This new era of work brings new opportunities, but it requires an adaptive leadership approach. Leaders who understand that the old ways of hiring based on degrees and pedigree no longer make sense will be the ones to succeed. In 2023, this shift will start to play out on a much bigger scale and will move from the margins to the mainstream, as employers start to realize the untapped potential we unlock by transitioning toward a skills-first labor market. WIRED has teamed up with Jobbio to create WIRED Hired, a dedicated career marketplace for WIRED readers. Companies who want to advertise their jobs can visit WIRED Hired to post open roles, while anyone can search and apply for thousands of career opportunities. Jobbio is not involved with this story or any editorial content.
business	/article/crypto-ftx-collapse-genesis-gemini	No One Will Escape the FTX Fallout	Genesis Global Trading, one of crypto’s oldest and most storied institutions, is in dire straits. In November, in the wake of the implosion of the crypto exchange FTX, the company’s lending unit was forced to freeze customer withdrawals—never a good sign. Almost two months later, Genesis is reportedly on the brink of bankruptcy.Although Genesis has not said publicly that bankruptcy is imminent (Derar Islim, interim CEO, says he remains “focused on finding a solution”), the firm is reported to have laid off 30 percent of its workforce this week—the latest sign of its financial ill-health.Founded in 2013, Genesis has become central to the crypto industry’s day-to-day operations. In 2021 alone, the company issued $131 billion in loans and set up $116.5 billion in trades. To fund these loans, Genesis borrows from individuals and institutions that own large quantities of coins, also known as whales, who receive a cut of profits in return. While the crypto hype train barreled on unchecked, Genesis was on a hot streak—but its luck ran out in 2022. The lender has been in trouble since July, when hedge fund Three Arrows Capital collapsed, taking with it $1.2 billion of the $2.36 billion it had borrowed from the firm. Genesis again found itself on the wrong side of a collapse in the autumn; when FTX filed for bankruptcy on November 11, the firm lost $175 million stored with the exchange.Digital Currency Group (DCG), parent company of Genesis, swooped in with bailouts on both occasions. Despite the assistance, the “unprecedented market turmoil” created by the FTX situation forced Genesis to freeze withdrawals and begin to hunt for emergency funding. But just like FTX, a rescue package for Genesis has not materialized.The frothiness of the crypto market in 2021 spread fear of missing out among investors that attracted huge sums of money. But that FOMO is now long gone, replaced by a suspicion of both the promises and accounting practices of large crypto companies in light of the allegations of fraud at FTX.Venture capital investment in crypto is drying up, according to a recent paper released by market data house PitchBook. After a “breakout year” in 2021, in which $21 billion of capital flooded into the industry, appetite for crypto investment is collapsing rapidly. By Q3 2022, funding was down 34.3 percent year-on-year, and the volume of deals had fallen to a two-year low.
business	/article/meta-horizon-workrooms-glitchy-company-trials	Does Meta’s Horizon Workrooms Deliver? Customers Say Yes … and No	In one of his first few VR meetings inside Meta’s Horizon Workrooms in December 2021, Eric Schudiske, the 48-year-old CEO of the tech-focused agency s2s Public Relations, showed his age. Speaking to his five-person team from a virtual conference room with a digitally rendered deer head on the wall and a view of a foggy evergreen forest, he was the sartorially backdated Gen Xer whose legless avatar showed up wearing a necktie. He’s since adopted a looser alter ego, as I observe in a recent internal Workrooms team meeting he invited me to join. Swiveling his chair towards a Zoom-like projection of my face on a curved screen hovering in the room, Schudiske touts a client’s upcoming grant meeting with Bill Gates—a “monocle and smoking jacket” affair, he calls it sardonically. Around a half-moon-shaped table, several blank-faced avatars shake their shoulders in apparent laughter. “Just hanging out with Bill Gates,” another staffer pipes in mid-sentence. This interruption reads differently than one on a typical video call. With Workroom’s distance and directionally modeled spatial audio, you can interject without the risk of inadvertently hijacking someone’s soliloquy. It’s one of the immersive mixed-reality features that Mike LeBeau, product management director for Workrooms, claims has taken Meta’s VR business offering to a key inflection point. It is now being beta tested by users at organizations such as NASA, PwC, automation software company The Bot Platform, and surgical training platform Osso VR. At many firms, Workrooms is being used to translate the kind of real-world “social presence” remote workers have missed in Hollywood Squares-style videoconferences to virtual conference rooms. Strapped into Quest 2 headsets that retail for about $400, or the more optically rich and expensive Quest Pro headsets (which cost $1,500), teams can conduct meetings, give presentations, host design reviews, and hold drop-in coworking hours—all while seemingly inhabiting the same room.Meta’s vision of the metaverse is starting to provide a “very tangible experience, and more important, for a very tangible utilitarian need, which is better remote work,” LeBeau says. The Tech Is Clunky, but More Affordable Than Ever Between 2019 and 2022, Meta pumped $36 billion into Reality Labs, which includes its metaverse and VR businesses. The venture saw a $30.7 billion loss over the same period. Now reports have emerged of a 13 percent workforce reduction, plunging stock value, declining ad revenue, and perhaps most worryingly, shrinking monthly active users inside Meta’s Horizon Worlds, the company’s signature VR social offering, which fell from around 300,000 to 200,000 users over the course of the year. Some skeptics are wondering whether Zoomed-out knowledge workers of the world want headsets to have weekly check-ins, scan spreadsheets, and exchange virtual high-fives and peace signs with their animated colleagues.“You can convince people to go into VR to play Star Wars and Batman,” said Brian Penny, a media strategist at ZEITG3IST, a digital marketing agency based in New York. “But you sincerely think people will spend $400 on a headset so they can spend their lives in an even duller, drabber, and more boring office than they already go to?”It’s a rhetorical question, but LeBeau’s statements when we met in Workrooms for an interview several weeks ago suggest he objects to the premise. For one thing, people don’t spend their lives in VR—typically sessions last 15 minutes to an hour, rarely more than two, he says. The cost is on average less than many smartphones, having come down considerably since the first-generation Oculus Rift debuted in 2016 for $600. “They have a pretty good lip-sync feature that looks natural when you’re talking, but when you stop talking, you start to smile a little bit, which is weird.” And although LeBeau declines to share specific figures, he says it helps retention among remote teams who want to talk through problems together, seemingly face to face. Updates planned for 2023 will make Workrooms more attractive to hybrid teams, he says. These include an option to view 3D models and a mixed reality experience, known as the Magic Room, which will let on-site and remote workers collaborate in the same shared space. Integrations with Zoom, Microsoft Teams, and Windows are also on the way in 2023.Early testers have mixed views as to whether the offering is ready for prime time. Trevor Ainge, a media and content specialist at s2s, says the first-person perspective of Workrooms—the feeling of occupying the same space as one’s colleagues and having to physically turn your body to meet someone’s gaze—is a marked improvement over Zoom or WebEX. 
business	/article/meta-surveillance-capitalism	The Slow Death of Surveillance Capitalism Has Begun	Surveillance capitalism just got a kicking. In an ultimatum, the European Union has demanded that Meta reform its approach to personalized advertising—a seemingly unremarkable regulatory ruling that could have profound consequences for a company that has grown impressively rich by, as Mark Zuckerberg once put it, running ads.The ruling, which comes with a €390 million ($414 million) fine attached, is targeted specifically at Facebook and Instagram, but it’s a huge blow to Big Tech as a whole. It’s also a sign that GDPR, Europe’s landmark privacy law that was introduced in 2018, actually has teeth. More than 1,400 fines have been introduced since it took effect, but this time the bloc’s regulators have shown they are willing to take on the very business model that makes surveillance capitalism, a term coined by American scholar Shoshana Zuboff, tick. “It is the beginning of the end of the data free-for-all,” says Johnny Ryan, a privacy activist and senior fellow at the Irish Council for Civil Liberties. To appreciate why, you need to understand how Meta makes its billions. Right now, Meta users opt in to personalized advertising by agreeing to the company’s terms of service—a lengthy contract users must accept to use its products. In a ruling yesterday, Ireland’s data watchdog, which oversees Meta because the company’s EU headquarters are based in Dublin, said bundling personalized ads with terms of service in this way was a violation of GDPR. The ruling is a response to two complaints, both made on the day GDPR came into force in 2018. Meta says it intends to appeal, but the ruling shows change is inevitable, say privacy activists. “It really asks the whole advertising industry, how do they move forward? And how do they move forward in a way that stops these litigations that require them to change constantly?” says Estelle Masse, global data protection lead at digital rights group Access Now.EU regulators did not tell Meta how to reform its operations, but many believe the company has only one option—to introduce an Apple-style system that asks users explicitly if they want to be tracked. Apple’s 2021 privacy change was a huge blow for companies that rely on user data for advertising revenue—Meta especially. In February 2022, Meta told investors Apple’s move would decrease the company’s 2022 sales by around $10 billion. Research shows that when given the choice, a large chunk of Apple users (between 54 and 96 percent, according to different estimates) declined to be tracked. If Meta was forced to introduce a similar system, it would threaten one of the company’s main revenue streams. 
business	/article/fishing-online-trading	Digital Traders Want to Go Fish	The chaos begins at 5 am. The markets open, the traders arrive, and the auction floor heaves. Over the next six hours, gambles are taken, hands are shaken, and deals are made in a flurry of brinkmanship, shouting, and testosterone.But this isn’t a Wall Street trading floor, and the commodity isn’t financial assets. Instead, the stock is of a different variety: fish. This is how fishermen auction their catch to primary processors who slice, dice, and prepare seafood for wholesalers, the last-mile delivery companies that supply restaurants, fishmongers, and supermarkets. A patchwork of 140,000 businesses make up the European seafood market, which trades more than €140 billion (about $148.5 billion) worth of fish every year. Despite those high numbers, it’s an industry predominantly conducted offline and resilient to disruption; besides phone calls and emails, the grandest use of technology may be the occasional WhatsApp message to a close contact in a fish buyer’s network.Edinburgh-based Rooser is beginning to change that. Its B2B seafood-trading platform connects buyers and sellers—the primary processors who supply the fish to wholesalers who demand it—across 13 European countries. Following his frustrations opening a fish factory in Aberdeenshire, Joel Watt founded the business in 2019 alongside Nicolas Desormeaux, Erez Mathan, and Thomas Quiroga. “You have 35,000 different types of seafood products moving on nothing but human emotion, with no central price information,” explains Watt. “It’s professional gambling: Buying a pile of fish with the hope of quickly selling it—it easily goes wrong.”In the fishing frenzy that moves catches up the supply chain—from the ocean to the icy boxes at auction to the trucks transporting the goods around the country and eventually to the plate—a piece of fish may end up changing hands seven times. The clock ticks down throughout the process: Traders are handling a depreciating asset. “You have a maximum of three days to move the fish on, or you’re dead,” says Desormeaux, a veteran commercial fish buyer based in the French port city of Saint-Malo, Brittany. “Once the truck leaves at midday, you have to wait for the next day. The longer you take, the greater your price-per-kilo losses become.”Mistakes are inevitably made in the daily rush. Watt and Desormeaux aim for Rooser to take the guesswork out of seafood trading. “I remember one Saturday night sitting on a harbor wall looking through my contacts trying to sell 10 tonnes of mackerel I’d accidentally bought,” says Watt. “Without a communication channel connecting everyone in the chain, you might overpay for a species from the Scottish market, only for its price to plummet once the Danish catch comes in, and you suddenly can’t sell.” Further complexity has been added to the supply chain by Brexit. “It’s introduced layers and layers of paperwork, creating more friction in moving fish between the EU and UK,” Watt says. A centralized marketplace doesn’t just benefit seafood traders. Watt says for every two pieces of fish consumed, another never makes it to the plate. By laying out all the information in real time, panic buying is reduced, sales are made faster, and less fish goes to waste. “It passes the shelf life on to the end consumer,” says Watt. “We’re the scoreboard in the middle of the process, allowing whoever wants to buy the fish to do so at the right price. Rather than have your team be on the phones all day trying to sell, you can now load all the information into a single point, going from one-to-one sales to one-to-many.”Having secured £17.5 million in an April funding round, Rooser next plans to scale globally and connect all the players in the worldwide seafood supply chain, even down to the individual boats and fisheries. The data harvested could be used to not only accurately track the carbon footprint of a piece of fish and improve its traceability for consumers—Rooser could eventually become the Google Maps for the fishing industry. “Every time a fishing net is taken out of the water, we’d be able to track where it’s been and map the ocean where the best fish are at different times of year,” says Watt. “We could then provide that data to governments to better manage fish stocks in a data-driven way.”Seafood is a traditional business. Generations of hardy seafarers form its backbone, supplemented by seasoned traders and straight-talking businesspeople, all looking to maximize profits and sniff out others’ weaknesses. Roosers’ founders, however, grew up in the industry: They’re eager to stress that they aren’t trying to be disruptors, but innovators. “If you tell someone in this world what their grandpa did was shit, you’re history,” says Desormeaux. “If you say you have new methodologies, technologies, and systems to better facilitate their daily business, and all the knowledge still falls on them, then it works.”Yet for an industry built on toil, battle-hardened reputation, and long-term connections, the seafood trade has been relatively quick to adopt Rooser. “An older contact of mine said he would never use technology: ‘If you want to sell fish to me you have to call me every day,’” says Desormeaux. “Now, he buys on our platform and tells me to stop trying him over the phone—he’s too busy using our system.” This article was originally published in the November/December 2022 issue of WIRED UK magazine.
business	/article/encryption-faces-an-existential-threat-in-europe	Encryption Faces an Existential Threat in Europe	Andy Yen is positioning himself to be Europe’s answer to Google cofounder Larry Page. Like Google, Yen’s company Proton offers services including email, calendar, drive storage, and VPN, just with a privacy twist. All its products are encrypted. But unlike Google, nine-year-old Proton has had to try and grow its business in the shadow of the tech giants. That has been a huge disadvantage, says Yen, because companies like Google and Apple can exploit their dominance to nudge users to use their apps as well as their phones. If a person buys a Google Android or Apple iPhone, they are offered a default email service, search engine, and calendar app. “The defaults just so happen to be the services that [these companies] themselves provide,” complained Yen in 2021. He was well aware that people favor convenience. “What we know from studies is that 95 percent of people will not change the defaults.”But 2022 was the year the European Union finally took action. In March, the bloc’s lawmakers agreed on new rules designed to release the grip Big Tech has on European consumers and to help homegrown internet companies compete with American giants for customers. The Digital Markets Act will obligate companies that run phone operating systems to offer “choice screens” so users have more control over which services they use. Technically, the DMA went into force in November, although it may not take full effect until March 2024. Proton is headquartered in Geneva, Switzerland, which is not an EU member. But Yen thinks this law will help European companies, like Proton, finally have a voice in Brussels.Europe’s momentum in rewriting the rules of the internet, however, is not all good for Proton, which has grown to 70 million accounts. The company is warily watching a wave of proposals in the UK and the EU that privacy advocates warn will threaten encryption, such as the UK’s Online Safety Bill and the EU’s proposals to combat child sexual abuse material. Yen spoke in October at WIRED’s business conference, WIRED Smarter. At the event, we talked about how he is thinking about the breakthroughs and concerns that are emerging out of Europe’s increasing focus on technology legislation. This interview has been edited for clarity and length.  
business	/article/happiness-startups-economy-labor	Happiness Should Be the Most Important KPI for Tech Employers	During economic downturns, businesses resort to muscle memory and do what they’ve done before. That often means budget cuts—and the deepest cuts commonly target technology investment and people.This time, however, things already feel very different. Businesses increasingly see their tech talent as a hard-won strategic investment, which they are reluctant to lose.READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.New McKinsey & Company research discovered that 55 percent of 1,100 companies surveyed globally have found it challenging to hire key data and tech roles, such as data and software engineers, data architects, machine learning engineers, and data scientists. And a majority said it’s only getting harder, despite offering even more attractive compensation packages and flexible work models.So, the real question for CEOs shouldn't be how to cut tech costs, but how to retain and excite their best tech talent. Or, put simply: How do you make them happy?Speaking to McKinsey, the tech investor Marc Andreessen said businesses should “find the smartest technologist in the company and make them CEO.” That doesn’t mean CEOs that can’t code are out of a job—most business leaders have never been a data scientist or software engineer—but they need to learn to be real advocates and enablers of this finite group of the best technologists. Beyond the coffee and foosball tables of the early 2000s, happy tech talent will gravitate to cultures where CEOs give them an active role in the business, treating them as innovators, not order-takers. The days of IT departments focusing primarily on gathering requirements and managing vendors are over. Instead, they are shifting from an output-focused culture to one where outcomes are the language of success. In an outcome-focused culture, businesses empower their tech talent to solve real problems with measurable, high-impact outcomes, rather than dictate what they should build top-down. Digital products drive a business forward and deliver sustainable and inclusive growth; projects have fixed budgets and timelines and are quickly disposed of when the going gets tough. You can’t build a successful product in a project management environment; tech talent burdened with that bureaucracy who feel they don’t have a seat at the business table will soon head toward the exit.If tech-talent happiness starts and ends with having a product culture, what if, in 2023, more CEOs were to think of themselves as chief product managers leading an outcome culture, in the same way that product managers think of themselves as “mini-CEOs”? This would create a working model that empowers small, cross-functional teams of brilliant (and happy!) engineers and designers with a clear mission to work on knotty problems with measurable outcomes that matter to—but are not suffocated by—the business or its processes. In other words: Let them focus on their craft. Retaining and making your tech talent successful has never mattered more. And a product culture is not just for tech companies; it’s also how more traditional companies start behaving like tech companies to compete. Almost all the big problems facing businesses today—whether it’s supply chain dislocation, stimulating customer demand, geopolitical tensions, or payment collection—will have technology-led answers. And when tech talent is configured correctly, the best solutions often come from the bottom up, not the top down. It will often be an engineer—with knowledge of the latest technologies and what’s actually feasible—who finds the way forward.That culture is critical if businesses want to not just retain talent, but move fast, create value, and be resilient in the face of the cacophony of headwinds.Tech talent expects clear targets and rapid feedback loops to know whether they are hitting the mark. In return, the best businesses in 2023 will make tech talent “happiness” a primary measure of success. 
business	/article/remote-work-office-labor	The Work-From-Anywhere War Is Beginning	Who calls the shots on how many days you end up working in the office? It has gradually dawned on bosses that it isn’t them. The real power holders? The elusive “top talent” that every firm is trying to attract. READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.Raj Choudhury, an economist from Harvard Business School, argues that throughout history it’s been the most sought-after job candidates who end up shaping what our jobs look like. For instance, in the early ’90s, using email on our phones was a luxury exclusive to CEOs. Soon, however, top talent in companies started demanding it and, as a result, we now can’t escape email. Today, Choudhury’s spidey-sense is tingling over the demand for extreme flexibility: Top talent doesn’t just want hybrid work, they want to work from wherever they want. “There are two kinds of companies,” Choudhury explains. “One is going to embrace work-from-anywhere, and the second is in denial—I feel those companies will lose their workforce.” He argues that the “companies that are trying to drag back time will lose some of their best talent, and that dynamic will force these companies to catch up.”This might come as a revelation to workers who are currently experiencing a top-down model of 3/2 in their workplaces. This “three days in, two days out” model was certainly expected to become a norm when we first imagined, during the pandemic, what life would be like after Covid. But since emerging from our bedrooms and kitchen tables we’ve recognized that we’re not at the end of this story—we’re still at the beginning of it. Data by Stanford economist Nick Bloom backs this up: In June 2020, most companies expected employees to be working from home around one and a half days a week, but the subsequent two years have seen the expectation of homeworking go up each successive month—most firms now expect workers to be at home for almost half of the week.Nimble startup firms have a strong advantage due to this cultural shift. Indeed, in 2023, we will see startups migrate to remote-first. On the other hand, more established firms will be presented with the decision of whether to hang on to expensive real estate and slow-to-evolve managers, or to just dash to chase the new trend.This will not be an easy transition. For instance, according to a report by workplace research firm Leesman, office-based working has been most popular with one group alone—senior leaders who had their own offices (or private meeting spaces). As a result, in 2023, veteran corporate managers will likely use the economic downturn to do a final attempt of dragging workers back to the office. It’s implausible to imagine that these more traditional managers might be rubbing their hands at the prospect of a short economic slowdown ahead, but using a softer job market as leverage to bring employees back to the office could prove a popular strategy. It might be too late; top talent has already made its mind up. There could be conflict ahead as it resolves itself.
business	/article/amazon-mince-pies	Amazon Has Conquered Christmas—but Its Reign May Be Ending	The problem with Amazon’s own-brand mince pies is that they’re delicious. For years, the ecommerce giant has stuck its fingers into every pie going—Amazon wind farms and an Amazon airline are no longer something to Amazon Blink at. Yet now Jeff Bezos has stuck his finger in the pie pie: For £2.04 ($2.50), British Amazon customers can get six deep-filled “by Amazon” mince pies delivered to their door. (For those unfamiliar, a mince pie is an individual spiced fruit Christmas treat with absolutely no meat in it, no matter what that one American food blog said in 2019.)And yes, the trouble is that Amazon’s taste great; they’re packed with orange peel, French brandy, port, and apple mincemeat (thankfully not Apple mincemeat, though it’s only a matter of time). The pastry is crumbly and sweet. The filling—rich and generous—shares at least one thing in common with Amazon’s founder. And so with every bite it becomes harder to resist the gradual monopolization of the entire planet by a man who throws his head back when he laughs. Photograph: AmazonIn 2019, US senator Elizabeth Warren vowed to break up “big tech companies” that have “too much power over our economy, our society, our democracy, and our little Christmas treats.” (She might not have said that last one.) Concerns were growing about Amazon rigging search results to favor its own brands over competitors’ products—a practice the company denied. Still, Amazon seemingly scaled back promotions of its private-label products as a result. Things looked good for third-party sellers when, also in 2019, research by ecommerce analysts Marketplace Pulse found that “Amazon-owned private-label brands are not nearly as successful as many paint them to be.” The report found that only 1.7 percent of the top 500,000 search terms on Amazon result in a customer clicking on an AmazonBasics-branded product.Except … two years later, in 2021, Amazon came out with its own mince pies. Does it matter that I don’t know who makes them—that their pretty purple box is ominously signed by an anonymous figure known only as “The Baker”? Alas, no, because they taste better than the pies offered by at least two major British supermarkets. With their humble silver-foiled bottoms and sugar-coated tops, they could be the most disruptive tech product of the past decade. In such an environment, how can Mom’s home baking compete? Customers seem to agree. Amazon’s mince pies have a 4.4 rating out of 5 after 117 ratings; reviews indicate that someone named John and someone named Sandra continued to buy them well into January. So is this it, the final nail in the coffin, the last time we try to resist our new insect overlords? Perhaps not. While Amazon may have mastered the mince and conquered Christmas, it might be too late. According to The Wall Street Journal, Amazon began cutting back on its private-label products this summer after poor sales. While it’s unclear whether Amazon’s food brands will also get the chop, the company still only controls 2.4 percent of the US grocery market, even after purchasing Whole Foods for $13.7 billion in 2017. Amazon Pieme may not be enough to turn things around. If you told most Brits that Amazon had nestled into the beloved Christmas treats market and started making its own mince pies, they’d be bewildered. In August, Amazon halted its rollout of brick-and-mortar Amazon Fresh stores across the UK after sales were poorer than expected in its existing 19 shops. Caveat: That might have something to do with the fact that I managed to grab my mince pies and walk out of the store without checking out (thanks to sensors, this is how the high-tech store operates) and without paying (this is not how the high-tech store operates; my card payment failed, but I wasn’t notified until later).As lip-smacking, waist-pinching grandmas have long told us, there’s no such thing as a truly guilt-free mince pie. Buy Amazon’s and you might just bolster the company least in need of bolstering in the entire world. But also—truthfully, regrettably, Ghost-of-Christmas-Future-is-shaking-his-head-at-you-lly—you’re going to have a delicious time.
business	/article/business-economy-transformation	Transformative Businesses Are Born in Tough Times	It’s been a rough year for entrepreneurs. Funding has been tight, top-flight leaders have been harder to lure away from secure corporate jobs, and marketing and discretionary spending has been at a standstill. Economic crunches are no fun for anyone, but when you’re trying to build a global business from scratch, the headwinds feel like a typhoon.READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.If we take a longer view, though, there’s good reason for optimism. Historically, the most exciting and generation-defining startups have been those built in challenging times. Think of Facebook, launched in 2004, in the shadow of the dotcom bust. Google also raised capital in this period and managed to grow through the broader economic slowdown. Fintech companies like Square and Stripe were founded in the wake of the 2008 subprime crisis, which dented confidence in mainstream finance.Why might this be? First, different economic cycles attract different kinds of entrepreneurs. When money is running hot, investors meet plenty of “momentum” founders: people who are riding a wave, and who can easily find another job if things don’t work out. But entrepreneurs who build companies after a downturn are a different bunch. They usually have a meaningful vision that they’re going to realize, no matter what, and they tend to be relentless in pursuing it. With fewer job opportunities to fall back on, they—and their employees—will naturally be more attached to the success of the company. This kind of dedication filters for those who can relentlessly execute, and it generates companies poised to better take advantage of opportunities when economic conditions improve.A second benefit of starting a business in a downturn is the shortage of competition. In bull markets, there might be a dozen other businesses trying to outcompete you in almost any sector. But during a recession, there will be fewer people trying to get a cut of the action. This leaves the space wide open for motivated entrepreneurs to seize the first-mover’s advantage and claim the market.Finally, companies created after a crash also find it easier to source the talent they need. When the business cycle is in an upturn, attracting and retaining the right people to help you grow is often a founder’s number-one headache. Talented workers are flooded with opportunities and tend to jump between companies more frequently. But with fewer well-capitalized companies vying for talent, you might have a better chance nailing the right executive hire. These reasons show why, in 2023, we can expect the launch of the most transformative companies of the coming decade. The type of businesses that will bloom will be a direct response to the many crises that have affected us in the past few years: Covid, the war in Ukraine, record temperatures and wildfires caused by climate breakdown.For example, because of the pandemic and the pressure on health care systems around the world, expect to see an upswell in companies seizing opportunities in health care and pharma. These will include AI-powered medical technologies that tackle the systemic problems of national health care systems and the use of mRNA vaccines to tackle other diseases like malaria and diabetes. Another major trend concerns climate and the environment. Many entrepreneurs today are gearing up to address environmental problems and the second-order consequences head-on, targeting sectors like energy, transportation, manufacturing, and finance, among others. Escalating geopolitical tensions, from China to Ukraine, have also brought questions of security, autonomy, and stability to the fore. This new geopolitical environment will result in opportunities for new companies in strategic areas like defense, hardware, cybersecurity, energy, and food.In 2023, businesses tackling the enormous challenges that confront society might not start out looking like world-beating companies. They’ll have to be scrappy, resourceful, and lean. But you can be sure, in a decade’s time, they’ll be the names on everyone’s lips.
business	/article/direct-to-consumer-business	Direct-to-Consumer Is Dying. It’s Time for a New Paradigm	In the past decade, storied brands like meal-replacement Huel and men’s grooming company Harry’s built multibillion-dollar retail businesses by using social media and digital-first advertising to sell directly to consumers online, without the need for middlemen. These brands were exemplars of a new form of retail, called direct-to-consumer (DTC). READ MOREThis story is from the WIRED World in 2023, our annual trends briefing. Read more stories from the series here—or download or order a copy of the magazine.The global pandemic only accelerated this trend, with many high-street stores being forced to close and to keep driving sales by going direct to shoppers online. Some brands successfully navigated the transition, like outdoor pizza oven maker Ooni, whose sales exploded during lockdown, with annual revenue up from £13.7 million ($167 million) in 2019 to £52.7 million in 2020. Shoppers also adapted—around 60 percent purchased from a direct-to-consumer brand at least once in 2021.As the pandemic slowly recedes, the market is again changing rapidly. Older, more established brands have now embraced the DTC approach—Nike’s direct-to-consumer sales in 2021, for instance, grew 30 percent to $16.5 billion. On the other hand, stocks of some of the biggest, publicly listed DTC brands—such as Warby Parker and Allbirds—have dropped as much as 64 percent in 2022.There are obvious economic factors behind this underperformance. The rebalancing of the economy, with inflation rising and squeezed supply chains, is piling the pressure on retailers. According to a report by McKinsey, rising prices are the number one concern for two thirds of UK consumers, with approximately 70 percent saying that they have recently changed their shopping habits and are more open than ever to buy cheaper brands. But other factors are at play in the recent crash of DTC brands. For instance, in 2021, Apple introduced a new transparency feature, which allowed users to opt out of app tracking, making it harder and more expensive for these brands to acquire new customers via paid social media advertising.As a result of these market forces, in 2023, DTC retail will evolve into a new, more resilient iteration which I call connect-to-consumer (CTC). This new approach is about taking many pathways to reach customers simultaneously: From social media to Web3, from online shopping to the high-street stores.To adopt it, brands will need to be creative about how they tell their story and grow their communities on these four different platforms. Consider the example of fitness apparel brand Gymshark, which in July opened a pop-up barbershop staffed with mental-health trained barbers to encourage men to open up about their problems while receiving a trim. Men’s make-up brand War Paint, on the other hand, is turning abandoned stores into showrooms for online buyers.Much experimentation with the CTC model is also happening on social media platforms. Kylie Jenner, for instance, is using TikTok Shopping—a new feature launched in 2022 in partnership with Shopify that allows users to link their TikTok accounts to their online stores—enabling her followers to buy directly from Kylie Cosmetics on the platform. According to Shopify, orders made on social media channels quadrupled in the first quarter of 2022. This retail opportunity extends to YouTube. British YouTube influencer Gabriella, for instance, uses her channel to sell stationery to nearly 900,000 followers. United Stand, an unofficial Manchester United fan channel with 1.4 million followers, also sells merchandise to its community via YouTube and Shopify. Web3 is also creating new opportunities for brands to connect with consumers. You might even have a token or NFT in your digital wallet to unlock an exclusive offer online or a VIP experience on the high street. This is already hitting the mainstream, with Starbucks rolling out a Web3-based rewards program to give customers exclusive perks. The retailers who will win in 2023 are those focused on building authentic connections to their customers through all of these avenues. These businesses will thrive by becoming channel-agnostic: The tools exist now to operate a store everywhere, reaching hundreds on the high street to billions on YouTube and TikTok, as well as niche communities in Web3.
